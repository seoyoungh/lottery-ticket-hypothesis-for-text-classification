{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UrbKXIUGWS3R"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 65
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 982,
     "status": "ok",
     "timestamp": 1587949459275,
     "user": {
      "displayName": "Seoyoung Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjITIRuMxnapYLrcCepnJsCF3Rb52KogXDd9B-Mhg=s64",
      "userId": "04592586031163595245"
     },
     "user_tz": -540
    },
    "id": "mVTivRv2xPpU",
    "outputId": "e0cec82f-c80e-4983-c9a3-f72e7627f807"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available devices  1\n",
      "Current cuda device  0\n",
      "Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "# GPU Check\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print ('Available devices ', torch.cuda.device_count())\n",
    "print ('Current cuda device ', torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 32
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 636,
     "status": "ok",
     "timestamp": 1587948405920,
     "user": {
      "displayName": "Seoyoung Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjITIRuMxnapYLrcCepnJsCF3Rb52KogXDd9B-Mhg=s64",
      "userId": "04592586031163595245"
     },
     "user_tz": -540
    },
    "id": "OU8OIZFNxM5w",
    "outputId": "8b021eb7-0a7b-438d-d4ba-f485152de701"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPU address is grpc://10.11.126.82:8470\n"
     ]
    }
   ],
   "source": [
    "# TPU Check\n",
    "\n",
    "assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n",
    "TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
    "print('TPU address is', TPU_ADDRESS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6vrOF0emVmwQ"
   },
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from torchtext.vocab import GloVe\n",
    "import random\n",
    "\n",
    "# Approach 1:\n",
    "# set up fields\n",
    "# TEXT = data.Field(lower=True, include_lengths=True, batch_first=True)\n",
    "# LABEL = data.Field(sequential=False)\n",
    "\n",
    "SEED = 1234 # Random Seed for reproductivity\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "TEXT = data.Field(tokenize = 'spacy')\n",
    "LABEL = data.LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 98877,
     "status": "ok",
     "timestamp": 1587949566555,
     "user": {
      "displayName": "Seoyoung Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjITIRuMxnapYLrcCepnJsCF3Rb52KogXDd9B-Mhg=s64",
      "userId": "04592586031163595245"
     },
     "user_tz": -540
    },
    "id": "ZDVjQ2sU0QMG",
    "outputId": "b7b18c71-c0a6-4c43-85f3-5965a290da92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading aclImdb_v1.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:07<00:00, 11.3MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 25000\n",
      "Number of testing examples: 25000\n",
      "{'text': ['Please', 'see', 'also', 'my', 'comment', 'on', 'Die', 'Nibelungen', 'part', '1', ':', 'Siegfried.<br', '/><br', '/>The', 'second', 'part', 'of', 'UFA', 'studio', \"'s\", 'gargantuan', 'production', 'of', 'the', 'Nibelungen', 'saga', 'continues', 'in', 'the', 'stylised', ',', 'symphonic', 'and', 'emotionally', 'detached', 'manner', 'of', 'its', 'predecessor', '.', 'However', ',', 'whereas', 'part', 'one', 'was', 'a', 'passionless', 'portrayal', 'of', 'individual', 'acts', 'of', 'heroism', ',', 'part', 'two', 'is', 'a', 'chaotic', 'depiction', 'of', 'bloodletting', 'on', 'a', 'grand', 'scale.<br', '/><br', '/>As', 'in', 'part', 'one', ',', 'director', 'Fritz', 'Lang', 'maintains', 'a', 'continuous', 'dynamic', 'rhythm', ',', 'with', 'the', 'pace', 'of', 'the', 'action', 'and', 'the', 'complexity', 'of', 'the', 'shot', 'composition', 'rising', 'and', 'falling', 'smoothly', 'as', 'the', 'tone', 'of', 'each', 'scene', 'demands', '.', 'These', 'pictures', 'should', 'only', 'be', 'watched', 'with', 'the', 'note', '-', 'perfect', 'Gottfried', 'Huppertz', 'score', ',', 'which', 'fortunately', 'is', 'on', 'the', 'Kino', 'DVD', '.', 'Now', ',', 'with', 'this', 'focus', 'on', 'mass', 'action', ',', 'Lang', 'is', 'presented', 'with', 'greater', 'challenges', 'in', 'staging', '.', 'The', 'action', 'sequences', 'in', 'his', 'earliest', 'features', 'were', 'often', 'badly', 'constructed', ',', 'but', 'now', 'he', 'simply', 'makes', 'them', 'part', 'of', 'that', 'rhythmic', 'flow', ',', 'with', 'the', 'level', 'of', 'activity', 'on', 'the', 'screen', 'swelling', 'up', 'like', 'an', 'orchestra.<br', '/><br', '/>But', 'just', 'as', 'part', 'one', 'made', 'us', 'witness', 'Siegfried', \"'s\", 'adventures', 'matter', '-', 'of', '-', 'factly', 'and', 'without', 'excitement', ',', 'part', 'two', 'presents', 'warfare', 'as', 'devastating', 'tragedy', '.', 'In', 'both', 'pictures', ',', 'there', 'is', 'a', 'deliberate', 'lack', 'of', 'emotional', 'connection', 'with', 'the', 'characters', '.', 'That', \"'s\", 'why', 'Lang', 'mostly', 'keeps', 'the', 'camera', 'outside', 'of', 'the', 'action', ',', 'never', 'allowing', 'us', 'to', 'feel', 'as', 'if', 'we', 'are', 'there', '(', 'and', 'this', 'is', 'significant', 'because', 'involving', 'the', 'audience', 'is', 'normally', 'a', 'distinction', 'of', 'Lang', \"'s\", 'work', ')', '.', 'That', \"'s\", 'also', 'why', 'the', 'performances', 'are', 'unnaturally', 'theatrical', ',', 'with', 'the', 'actors', 'lurching', 'around', 'like', 'constipated', 'sleepwalkers.<br', '/><br', '/>Nevertheless', ',', 'Kriemhild', \"'s\", 'revenge', 'does', 'constantly', 'deal', 'with', 'emotions', ',', 'and', 'is', 'in', 'fact', 'profoundly', 'humanist', '.', 'The', 'one', 'moment', 'of', 'naturalism', 'is', 'when', 'Atilla', 'holds', 'his', 'baby', 'son', 'for', 'the', 'first', 'time', ',', 'and', 'Lang', 'actually', 'emphasises', 'the', 'tenderness', 'of', 'this', 'scene', 'by', 'building', 'up', 'to', 'it', 'with', 'the', 'wild', ',', 'frantic', 'ride', 'of', 'the', 'huns', '.', 'The', 'point', 'is', 'that', 'Lang', 'never', 'manipulates', 'us', 'into', 'taking', 'sides', ',', 'and', 'in', 'that', 'respect', 'this', 'version', 'has', 'more', 'in', 'common', 'with', 'the', 'original', 'saga', 'than', 'the', 'Wagner', 'opera', '.', 'The', 'climactic', 'slaughter', 'is', 'the', 'very', 'antithesis', 'of', 'a', 'rousing', 'battle', 'scene', '.', 'Why', 'then', 'did', 'Hitler', 'and', 'co.', 'get', 'so', 'teary', '-', 'eyed', 'over', 'it', ',', 'a', 'fact', 'which', 'has', 'unfairly', 'tarnished', 'the', 'reputation', 'of', 'these', 'films', '?', 'Because', 'the', 'unwavering', 'racial', 'ideology', 'of', 'the', 'Nazis', 'made', 'them', 'automatically', 'view', 'the', 'Nibelungs', 'as', 'the', 'good', 'guys', ',', 'even', 'if', 'they', 'do', 'kill', 'babies', 'and', 'betray', 'their', 'own', 'kin', '.', 'For', 'Hitler', ',', 'their', 'downfall', 'would', 'always', 'be', 'a', 'nationalist', 'tragedy', ',', 'not', 'a', 'human', 'one.<br', '/><br', '/>But', 'for', 'us', 'non', '-', 'nazi', 'viewers', ',', 'what', 'makes', 'this', 'picture', 'enjoyable', 'is', 'its', 'beautiful', 'sense', 'of', 'pageantry', 'and', 'musical', 'rhythm', '.', 'When', 'you', 'see', 'these', 'fully', '-', 'developed', 'silent', 'pictures', 'of', 'Lang', \"'s\", ',', 'it', 'makes', 'you', 'realise', 'how', 'much', 'he', 'was', 'wasted', 'in', 'Hollywood', '.', 'Rather', 'than', 'saddling', 'him', 'with', 'low', '-', 'budget', 'potboilers', ',', 'they', 'should', 'have', 'put', 'him', 'to', 'work', 'on', 'a', 'few', 'of', 'those', 'sword', '-', 'and', '-', 'sandal', 'epics', ',', 'pictures', 'that', 'do', 'not', 'have', 'to', 'be', 'believable', 'and', 'do', 'not', 'have', 'to', 'move', 'us', 'emotionally', ',', 'where', 'it', \"'s\", 'the', 'poetic', ',', 'operatic', 'tonality', 'that', 'sweeps', 'us', 'along', '.'], 'label': 'pos'}\n"
     ]
    }
   ],
   "source": [
    "train, test = datasets.IMDB.splits(TEXT, LABEL)\n",
    "\n",
    "print(f'Number of training examples: {len(train)}')\n",
    "print(f'Number of testing examples: {len(test)}')\n",
    "\n",
    "print(vars(train.examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8kXszQyI0VXI"
   },
   "outputs": [],
   "source": [
    "# make splits for data\n",
    "# by default this splits 70:30\n",
    "\n",
    "train, valid = train.split(random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 886,
     "status": "ok",
     "timestamp": 1587949575969,
     "user": {
      "displayName": "Seoyoung Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjITIRuMxnapYLrcCepnJsCF3Rb52KogXDd9B-Mhg=s64",
      "userId": "04592586031163595245"
     },
     "user_tz": -540
    },
    "id": "gT9phDVs0uap",
    "outputId": "a253c46e-721a-4ee5-8fd3-de0c282e3f81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.fields {'text': <torchtext.data.field.Field object at 0x7f54ca698c18>, 'label': <torchtext.data.field.LabelField object at 0x7f54ca698c50>}\n",
      "Number of training examples: 17500\n",
      "Number of validation examples: 7500\n",
      "Number of testing examples: 25000\n"
     ]
    }
   ],
   "source": [
    "print('train.fields', train.fields)\n",
    "print(f'Number of training examples: {len(train)}')\n",
    "print(f'Number of validation examples: {len(valid)}') \n",
    "print(f'Number of testing examples: {len(test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XGRcN3Ia2Mw8"
   },
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 25_000\n",
    "\n",
    "TEXT.build_vocab(train, max_size = MAX_VOCAB_SIZE)\n",
    "LABEL.build_vocab(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 541,
     "status": "ok",
     "timestamp": 1587949581158,
     "user": {
      "displayName": "Seoyoung Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjITIRuMxnapYLrcCepnJsCF3Rb52KogXDd9B-Mhg=s64",
      "userId": "04592586031163595245"
     },
     "user_tz": -540
    },
    "id": "FPFHHhh_2RFZ",
    "outputId": "d4ba23b8-96fc-428d-e6bf-0a3a7e0caf82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 25002\n",
      "Unique tokens in LABEL vocabulary: 2\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
    "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 893,
     "status": "ok",
     "timestamp": 1587949583425,
     "user": {
      "displayName": "Seoyoung Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjITIRuMxnapYLrcCepnJsCF3Rb52KogXDd9B-Mhg=s64",
      "userId": "04592586031163595245"
     },
     "user_tz": -540
    },
    "id": "E-9G7NjC2m59",
    "outputId": "3e9da1f3-72a7-4983-d079-2d6b40f8b5e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 201852), (',', 192394), ('.', 164699), ('and', 109095), ('a', 108947), ('of', 100771), ('to', 93575), ('is', 75983), ('in', 61025), ('I', 54169), ('it', 53440), ('that', 49044), ('\"', 44304), (\"'s\", 43028), ('this', 42340), ('-', 37076), ('/><br', 35552), ('was', 35060), ('as', 30419), ('with', 29688)]\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.freqs.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5613,
     "status": "ok",
     "timestamp": 1587949589654,
     "user": {
      "displayName": "Seoyoung Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjITIRuMxnapYLrcCepnJsCF3Rb52KogXDd9B-Mhg=s64",
      "userId": "04592586031163595245"
     },
     "user_tz": -540
    },
    "id": "bXuc3_vj2r2m",
    "outputId": "40d8d510-1f22-4633-bfc5-576fca5d1923"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is']\n",
      "defaultdict(<function _default_unk_index at 0x7f54c2a851e0>, {'neg': 0, 'pos': 1})\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.itos[:10])\n",
    "print(LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VIAPS1492vMa"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train, valid, test), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RGDsjKsu6KhI"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        \n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, text):\n",
    "\n",
    "        #text = [sent len, batch size]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "        \n",
    "        #embedded = [sent len, batch size, emb dim]\n",
    "        \n",
    "        output, hidden = self.rnn(embedded)\n",
    "        \n",
    "        #output = [sent len, batch size, hid dim]\n",
    "        #hidden = [1, batch size, hid dim]\n",
    "        \n",
    "        assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
    "        \n",
    "        return self.fc(hidden.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ElIs9DCv6Nb5"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "\n",
    "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 32
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 834,
     "status": "ok",
     "timestamp": 1587949600907,
     "user": {
      "displayName": "Seoyoung Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjITIRuMxnapYLrcCepnJsCF3Rb52KogXDd9B-Mhg=s64",
      "userId": "04592586031163595245"
     },
     "user_tz": -540
    },
    "id": "IahKYfG86PcX",
    "outputId": "ebd96144-d08a-4de5-84be-c8a0609bf4bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 2,592,105 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mtBIRjRm6RPh"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MYVGFhhB6SrP"
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6IiQ6ZPM6UoO"
   },
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J47UDj3o6Wb2"
   },
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7c42EhhN6YmH"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        predictions = model(batch.text).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.label)\n",
    "        \n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GBnG3zLj6Zga"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.text).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.label)\n",
    "            \n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7aaarsbv6bEi"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20651,
     "status": "ok",
     "timestamp": 1587949647998,
     "user": {
      "displayName": "Seoyoung Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjITIRuMxnapYLrcCepnJsCF3Rb52KogXDd9B-Mhg=s64",
      "userId": "04592586031163595245"
     },
     "user_tz": -540
    },
    "id": "GbzymLeiIqSL",
    "outputId": "8cae53bb-7954-47d7-b711-829706d6b19a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E-OXfuI5IkTx"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/content/drive/My Drive/lottery-ticket-hypothesis-for-text-classification/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 75202,
     "status": "ok",
     "timestamp": 1587949727531,
     "user": {
      "displayName": "Seoyoung Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjITIRuMxnapYLrcCepnJsCF3Rb52KogXDd9B-Mhg=s64",
      "userId": "04592586031163595245"
     },
     "user_tz": -540
    },
    "id": "kYinFOkS6dnu",
    "outputId": "77ee53bc-454c-4fb5-db4f-137251cdf110"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 15s\n",
      "\tTrain Loss: 0.694 | Train Acc: 50.12%\n",
      "\t Val. Loss: 0.697 |  Val. Acc: 49.95%\n",
      "Epoch: 02 | Epoch Time: 0m 14s\n",
      "\tTrain Loss: 0.693 | Train Acc: 49.93%\n",
      "\t Val. Loss: 0.697 |  Val. Acc: 49.93%\n",
      "Epoch: 03 | Epoch Time: 0m 14s\n",
      "\tTrain Loss: 0.693 | Train Acc: 50.17%\n",
      "\t Val. Loss: 0.697 |  Val. Acc: 50.86%\n",
      "Epoch: 04 | Epoch Time: 0m 14s\n",
      "\tTrain Loss: 0.693 | Train Acc: 49.59%\n",
      "\t Val. Loss: 0.697 |  Val. Acc: 49.50%\n",
      "Epoch: 05 | Epoch Time: 0m 14s\n",
      "\tTrain Loss: 0.693 | Train Acc: 50.03%\n",
      "\t Val. Loss: 0.697 |  Val. Acc: 49.92%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 32
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4710,
     "status": "ok",
     "timestamp": 1587949747085,
     "user": {
      "displayName": "Seoyoung Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjITIRuMxnapYLrcCepnJsCF3Rb52KogXDd9B-Mhg=s64",
      "userId": "04592586031163595245"
     },
     "user_tz": -540
    },
    "id": "XbIuctSU6xii",
    "outputId": "a3e6f210-beed-4a9b-d4db-a05f44e4d1f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.710 | Test Acc: 47.39%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('tut1-model.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyP/9w3uLjDEHh/KnenOFx3R",
   "collapsed_sections": [],
   "name": "IMDb-simple-rnn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
