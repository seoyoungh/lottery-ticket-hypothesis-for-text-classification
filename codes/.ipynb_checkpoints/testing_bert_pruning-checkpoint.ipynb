{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gGhnQLvJatVS"
   },
   "source": [
    "# Bert Pruning\n",
    "\n",
    "[Used the pretained BERT](https://github.com/huggingface/transformers#Quick-tour-TF-20-training-and-PyTorch-interoperability)  \n",
    "[Reference Post](https://huffon.github.io/2020/03/15/torch-pruning/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 642
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7365,
     "status": "ok",
     "timestamp": 1587921541400,
     "user": {
      "displayName": "Seoyoung Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjITIRuMxnapYLrcCepnJsCF3Rb52KogXDd9B-Mhg=s64",
      "userId": "04592586031163595245"
     },
     "user_tz": -540
    },
    "id": "Zw5zfuOzZw4r",
    "outputId": "28d220df-2196-4e4f-b622-481adc66bc8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
      "\u001b[K     |████████████████████████████████| 573kB 3.4MB/s \n",
      "\u001b[?25hCollecting tokenizers==0.5.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
      "\u001b[K     |████████████████████████████████| 3.7MB 49.4MB/s \n",
      "\u001b[?25hCollecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/50/93509f906a40bffd7d175f97fd75ea328ad9bd91f48f59c4bd084c94a25e/sacremoses-0.0.41.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 19.8MB/s \n",
      "\u001b[?25hCollecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/2c/8df20f3ac6c22ac224fff307ebc102818206c53fc454ecd37d8ac2060df5/sentencepiece-0.1.86-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0MB 41.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.43)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
      "Requirement already satisfied: botocore<1.16.0,>=1.15.43 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.43)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.43->boto3->transformers) (2.8.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.43->boto3->transformers) (0.15.2)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.41-cp36-none-any.whl size=893334 sha256=d5f0cff7244c06785c7dc132c51bd4a073bc903970b0476ba84200034e056f1e\n",
      "  Stored in directory: /root/.cache/pip/wheels/22/5a/d4/b020a81249de7dc63758a34222feaa668dbe8ebfe9170cc9b1\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n",
      "Successfully installed sacremoses-0.0.41 sentencepiece-0.1.86 tokenizers-0.5.2 transformers-2.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YiGWMIhBb6qo"
   },
   "source": [
    "# Local Pruning\n",
    "> 모델 내 존재하는 텐서들을 개별적으로 가지치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 114,
     "referenced_widgets": [
      "20b9698fc2664b0aa133339d293fb4dd",
      "bf2e5a40256c41cdaabb73aa16f4a7da",
      "e249900b5a534ba6a6ce0ec666f2eaad",
      "6bdb804980d949e3852d675e9cfbfd2b",
      "cefb6c6667084eadb59730b3eea854fd",
      "55eec29e4bcd4cbc8d3449957cba4e4a",
      "1de7303e02da4b4f9f0c33b7694c1699",
      "a33b2f80b4e24f26a188ad1a604207d5",
      "bce0a4a3a6fa4920a22f288e3e1c8ddc",
      "d140d44d67214c809ce2db1b7007a5b9",
      "1ff8111a0070443baa6d77f3b1d941b5",
      "6bee764c91e24a81a47fd02048016b01",
      "98f5c2cd419340daba80571e7a05b1df",
      "c926e1a523534ee285b8cd14bf1820ae",
      "b1ec5e075fdf41dd9e8236d17f684e39",
      "d6ebd505ebbc4735a5cca84d338e7629"
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12992,
     "status": "ok",
     "timestamp": 1587921555784,
     "user": {
      "displayName": "Seoyoung Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjITIRuMxnapYLrcCepnJsCF3Rb52KogXDd9B-Mhg=s64",
      "userId": "04592586031163595245"
     },
     "user_tz": -540
    },
    "id": "i8BFvopAZlps",
    "outputId": "d5c40e67-ed1e-4b87-c864-394caf364060"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20b9698fc2664b0aa133339d293fb4dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=433, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bce0a4a3a6fa4920a22f288e3e1c8ddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=435779157, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.utils.prune as prune\n",
    "from transformers import BertModel\n",
    "\n",
    "model = BertModel.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 720,
     "status": "ok",
     "timestamp": 1587921775410,
     "user": {
      "displayName": "Seoyoung Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjITIRuMxnapYLrcCepnJsCF3Rb52KogXDd9B-Mhg=s64",
      "userId": "04592586031163595245"
     },
     "user_tz": -540
    },
    "id": "uh1kdGE3g1Sq",
    "outputId": "28afb0c4-e686-440d-b168-70fb068ddabd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 32
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 559,
     "status": "ok",
     "timestamp": 1587921559837,
     "user": {
      "displayName": "Seoyoung Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjITIRuMxnapYLrcCepnJsCF3Rb52KogXDd9B-Mhg=s64",
      "userId": "04592586031163595245"
     },
     "user_tz": -540
    },
    "id": "o6_Alpj5Z7Q0",
    "outputId": "1604baa0-f6e7-4f29-94a7-1a0cfde1013f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108310272"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 542,
     "status": "ok",
     "timestamp": 1587921562996,
     "user": {
      "displayName": "Seoyoung Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjITIRuMxnapYLrcCepnJsCF3Rb52KogXDd9B-Mhg=s64",
      "userId": "04592586031163595245"
     },
     "user_tz": -540
    },
    "id": "AxSe0IEXZ90d",
    "outputId": "668eda02-fe17-4a86-afab-9ac2de241679"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertSelfAttention(\n",
      "  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "module = model.encoder.layer[0].attention.self\n",
    "print(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 592,
     "status": "ok",
     "timestamp": 1587921570249,
     "user": {
      "displayName": "Seoyoung Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjITIRuMxnapYLrcCepnJsCF3Rb52KogXDd9B-Mhg=s64",
      "userId": "04592586031163595245"
     },
     "user_tz": -540
    },
    "id": "wXzQIQBiaW_1",
    "outputId": "398434b7-a4c7-46f0-d589-fe5ed2819fdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bias', Parameter containing:\n",
      "tensor([-4.5075e-04,  6.3931e-04, -1.3673e-04, -4.4833e-04, -4.8297e-04,\n",
      "         8.5335e-04, -6.2471e-04,  7.7209e-04, -4.6402e-04,  4.8441e-04,\n",
      "         9.7060e-05, -7.4744e-04, -1.4687e-03, -3.6819e-04, -4.6814e-04,\n",
      "         9.9541e-04, -3.0008e-03, -1.0790e-03, -1.6073e-04, -4.6535e-04,\n",
      "         5.6987e-04, -1.8128e-03,  2.0990e-03, -3.5929e-05,  2.1796e-04,\n",
      "         2.0506e-03, -8.8005e-04,  4.4442e-04,  6.4584e-04, -1.9093e-03,\n",
      "         4.4126e-04,  2.0759e-04, -1.5373e-04, -1.5536e-04,  3.5340e-05,\n",
      "        -4.4808e-04,  1.3942e-03,  5.9183e-04, -1.4158e-05,  8.4992e-04,\n",
      "        -7.8199e-04,  2.6565e-04, -1.9708e-03, -8.8281e-04, -9.4142e-04,\n",
      "        -1.0624e-04, -2.1437e-03,  1.9360e-04, -1.1071e-03, -6.4646e-04,\n",
      "         5.0200e-04, -7.7265e-04, -3.2641e-04,  3.1411e-05, -1.2639e-03,\n",
      "         4.9262e-04,  3.7519e-04, -5.6525e-05, -6.5781e-04,  4.6099e-04,\n",
      "        -2.4043e-03,  7.3155e-04, -1.6624e-03,  4.1991e-04,  5.2776e-06,\n",
      "        -1.9378e-03,  3.0003e-03, -8.9278e-04,  4.3344e-05,  2.5033e-03,\n",
      "        -6.4651e-04,  1.2104e-03, -1.0243e-03, -1.2653e-03, -5.8322e-04,\n",
      "        -1.2446e-03, -8.7324e-04,  1.5257e-04, -1.6892e-03, -2.2702e-04,\n",
      "         4.7292e-04, -1.9658e-03, -1.2071e-03, -1.1187e-03, -1.2895e-03,\n",
      "        -9.3685e-04,  1.3970e-03,  5.4844e-04, -1.3878e-03,  6.6890e-06,\n",
      "        -1.8691e-03, -9.3432e-04,  4.6209e-04,  3.1122e-04, -4.4163e-05,\n",
      "         1.7544e-03, -2.3810e-04, -2.5493e-03, -6.6575e-04,  5.4853e-04,\n",
      "        -2.4245e-03, -7.5354e-04, -2.0370e-03,  2.3277e-04,  3.4582e-03,\n",
      "         1.3604e-03,  1.2960e-03,  4.5274e-03, -1.0648e-03,  1.1124e-03,\n",
      "         1.5280e-03,  6.8583e-04, -3.5745e-04, -1.2804e-03, -4.6646e-04,\n",
      "         1.4927e-03, -7.9551e-04,  1.4773e-03, -7.8367e-04, -3.2938e-04,\n",
      "        -2.3481e-03,  1.6548e-04,  1.6505e-03, -1.1459e-03,  1.3988e-03,\n",
      "         1.5846e-03, -1.8112e-03,  2.6534e-03,  8.5451e-04, -1.8381e-04,\n",
      "        -2.9746e-04,  2.0692e-04,  9.4245e-05, -1.3992e-03,  1.1498e-04,\n",
      "        -4.6970e-04, -1.1821e-03, -2.2678e-03, -5.3473e-04,  2.3039e-04,\n",
      "         1.1064e-03, -6.4366e-04, -1.2395e-03, -2.9480e-05, -1.2138e-03,\n",
      "         4.0610e-04, -6.9925e-04,  5.4872e-04,  6.1843e-04,  9.3020e-04,\n",
      "         4.3791e-04, -8.8416e-05,  1.5406e-04,  9.0997e-04, -2.4790e-04,\n",
      "        -1.2500e-03,  1.9390e-04,  5.3811e-04, -8.8558e-04,  8.3321e-04,\n",
      "        -1.0934e-03,  5.1671e-04, -5.3213e-04, -1.5079e-03,  9.7987e-04,\n",
      "        -1.9925e-03, -5.9103e-04, -1.1471e-03, -1.3482e-03,  4.1966e-06,\n",
      "        -6.0771e-04,  6.7213e-04,  5.7242e-04,  1.4748e-04,  6.7059e-04,\n",
      "        -2.5242e-04, -1.2935e-03, -2.7342e-04, -3.1357e-03, -1.3709e-04,\n",
      "         8.4321e-06, -6.1891e-04, -4.6440e-04, -3.3269e-04, -1.0687e-03,\n",
      "        -7.0425e-04, -1.1379e-03, -5.8975e-04, -4.1942e-04, -8.9134e-04,\n",
      "         3.6225e-04,  1.2173e-03,  1.1709e-03,  1.0337e-03,  2.0972e-03,\n",
      "         4.6325e-03,  9.1117e-04,  7.0136e-03,  3.9219e-03, -9.6026e-04,\n",
      "        -7.1620e-03,  3.2062e-03, -2.2073e-03,  3.4789e-03, -8.8383e-04,\n",
      "        -5.5295e-04,  4.5864e-04, -2.4891e-03, -2.9448e-03, -2.6067e-03,\n",
      "        -3.1958e-03, -3.4512e-03,  2.4487e-03,  3.1093e-03,  1.4709e-03,\n",
      "        -1.0581e-03,  2.2739e-03, -5.8854e-03,  3.0629e-03,  2.3796e-04,\n",
      "        -1.7535e-03,  3.3720e-03, -1.0200e-03, -1.1698e-03,  2.8293e-03,\n",
      "         2.3649e-03,  3.9963e-03, -3.2470e-03, -7.0003e-03,  2.9345e-04,\n",
      "        -4.2233e-03,  3.7131e-04, -1.5399e-03, -4.4571e-04,  3.7502e-03,\n",
      "         7.2077e-03, -3.5842e-03,  3.5463e-03, -3.0626e-03,  3.4716e-03,\n",
      "        -9.8799e-04,  1.5825e-03,  1.7237e-03,  3.5100e-03, -3.2561e-04,\n",
      "         1.8846e-03,  7.2731e-03,  1.0541e-03, -4.7822e-03, -1.8538e-03,\n",
      "        -1.2346e-03, -2.4767e-04, -2.3871e-03,  2.2927e-03,  2.3214e-04,\n",
      "        -8.5822e-04,  2.8567e-03,  1.5331e-03, -1.0209e-04, -9.4502e-05,\n",
      "        -1.8115e-03,  9.8671e-04, -4.1052e-04, -2.8865e-03, -1.1590e-04,\n",
      "         4.4826e-04,  7.4345e-05, -4.4182e-04,  2.2170e-04, -2.6022e-03,\n",
      "         8.9430e-04,  4.0814e-03, -1.7227e-03, -1.6447e-03,  6.3763e-04,\n",
      "         7.9844e-04, -2.5195e-04, -2.8073e-04,  1.3934e-03,  8.8477e-04,\n",
      "         2.4402e-03,  2.6572e-03, -3.8261e-04, -3.5675e-03,  3.9919e-03,\n",
      "        -4.1065e-04,  1.6129e-03, -3.6500e-04, -5.0602e-04, -2.9292e-03,\n",
      "        -1.4711e-03, -2.2187e-03, -2.6717e-04, -2.0390e-03,  6.6572e-04,\n",
      "        -1.5454e-03, -2.0897e-04, -3.1104e-04, -9.1675e-05,  9.7432e-04,\n",
      "        -1.7890e-04,  7.0667e-04,  1.0518e-04, -1.1013e-03, -1.2165e-03,\n",
      "         9.5313e-04, -1.2669e-03,  5.0920e-04, -1.5487e-03,  1.0149e-03,\n",
      "        -7.4706e-04,  6.0163e-04, -4.6153e-05, -5.2320e-04, -5.5379e-04,\n",
      "         2.3721e-03, -1.1345e-03, -1.1679e-03, -1.0999e-03,  5.5690e-04,\n",
      "        -1.8064e-03,  5.2338e-04, -8.7620e-04, -1.1788e-03,  3.3634e-03,\n",
      "        -1.2350e-03, -6.2554e-04, -1.0900e-05,  7.3770e-04, -1.6454e-03,\n",
      "        -2.4058e-03, -2.0036e-03, -2.3530e-03, -4.1878e-04, -2.3022e-03,\n",
      "        -2.5860e-03,  9.8766e-04, -9.2863e-04, -7.6622e-04,  1.5469e-03,\n",
      "        -2.2305e-03,  1.0740e-03, -1.9992e-04,  4.2950e-03,  6.1812e-04,\n",
      "        -3.6555e-03, -3.9012e-03, -6.5666e-04, -9.3937e-04, -3.2627e-03,\n",
      "         9.7545e-04, -1.5124e-03, -1.8600e-03, -6.6509e-04,  1.0588e-03,\n",
      "         6.1127e-04,  1.3538e-03,  4.8610e-04, -3.7257e-05, -3.2132e-03,\n",
      "         2.3919e-03,  1.8338e-03,  3.4705e-03, -2.5586e-03,  5.2118e-04,\n",
      "        -2.7088e-03, -8.3863e-04, -1.1010e-03,  2.4027e-03,  1.2161e-03,\n",
      "         6.2238e-04, -3.2530e-03, -2.3460e-04, -1.8522e-05, -1.7832e-03,\n",
      "        -2.8128e-03, -4.2183e-04, -1.3625e-03,  1.0366e-03,  7.0225e-04,\n",
      "        -1.1659e-03,  6.2746e-05,  1.6689e-03,  3.4855e-04, -1.1422e-03,\n",
      "         9.1986e-04, -1.7182e-03, -7.6924e-04, -1.1435e-03,  1.7655e-03,\n",
      "         1.1915e-03,  1.1780e-03,  3.0245e-04, -1.4028e-04, -3.0104e-03,\n",
      "         2.3982e-03, -1.7224e-03,  7.0373e-04,  3.9824e-03, -1.6743e-04,\n",
      "        -9.7077e-04,  1.2812e-03, -1.1822e-04,  1.9302e-03,  1.3302e-03,\n",
      "         6.8155e-05, -2.3481e-03,  1.3737e-03,  1.6056e-04,  9.8859e-05,\n",
      "         5.8619e-04,  3.3607e-04,  9.9278e-04, -2.0128e-03,  1.0509e-03,\n",
      "         2.6307e-03,  6.9428e-04,  5.7091e-04, -6.7450e-04,  4.7832e-04,\n",
      "         1.3574e-03, -1.6465e-03, -4.5223e-04,  2.8580e-03,  1.5665e-03,\n",
      "        -2.7018e-04, -2.8117e-03, -3.6844e-03,  8.5407e-04, -3.4515e-03,\n",
      "         5.6900e-04, -7.8704e-04,  9.3086e-04,  1.6276e-03,  6.6189e-04,\n",
      "        -1.3816e-03,  8.7184e-04,  2.9130e-03, -6.6432e-04, -3.0845e-03,\n",
      "        -1.0382e-03, -8.2503e-04,  7.9967e-04, -2.7094e-04,  8.6063e-06,\n",
      "        -1.4261e-03,  1.4532e-03,  9.1169e-04,  1.9083e-04, -3.1608e-04,\n",
      "        -1.1374e-04, -2.5696e-05, -7.9211e-04, -1.2628e-03,  1.2918e-03,\n",
      "         6.2048e-04, -5.8662e-04,  1.2440e-03,  1.1432e-03, -3.3663e-04,\n",
      "         9.8559e-04,  7.5414e-04, -2.1163e-03, -2.3401e-04,  4.1029e-04,\n",
      "        -1.5389e-04, -2.1303e-04,  8.0477e-05,  1.5120e-04, -9.6375e-04,\n",
      "         6.6871e-04, -8.4291e-04, -2.0257e-04,  3.6672e-05,  4.2345e-04,\n",
      "         5.5477e-04,  8.9161e-04, -1.3884e-03, -7.9123e-04, -6.9587e-04,\n",
      "        -3.7094e-04, -1.1370e-03,  2.4306e-04, -3.6434e-04, -4.2379e-04,\n",
      "        -1.8570e-04, -1.0734e-04, -9.2729e-06, -3.7936e-04,  2.7610e-04,\n",
      "        -2.2923e-03, -1.3877e-04, -3.6226e-04,  4.3790e-05, -8.1488e-05,\n",
      "        -7.0583e-04,  3.8284e-04, -6.4710e-04,  3.5178e-04, -5.3818e-04,\n",
      "         1.2480e-03,  5.0027e-04, -4.4209e-04,  5.9019e-04,  7.3998e-04,\n",
      "        -3.2291e-04,  8.1916e-05,  4.5663e-04,  8.0259e-04,  1.6296e-03,\n",
      "        -2.8502e-04,  3.4830e-04, -2.8572e-05,  6.9768e-04,  1.1212e-03,\n",
      "         1.5246e-03,  4.7797e-04, -2.0629e-03, -1.8813e-03,  3.4155e-03,\n",
      "        -1.3322e-03,  2.1190e-04,  1.9147e-04, -4.7127e-04, -6.0859e-04,\n",
      "         1.8072e-03,  5.5468e-04, -1.9804e-03,  1.5034e-03, -4.7569e-04,\n",
      "        -1.2072e-03, -1.3745e-03, -1.0465e-03, -3.8901e-04, -2.6570e-04,\n",
      "         8.0261e-04,  1.5594e-03,  6.9251e-04, -7.4193e-05, -6.0562e-04,\n",
      "         1.1299e-03,  2.3621e-04,  1.0665e-03, -7.1161e-04,  3.1995e-03,\n",
      "         2.1107e-03,  5.9163e-05, -2.9844e-04, -1.3449e-03, -2.0177e-04,\n",
      "         1.3499e-03, -1.7493e-03,  5.1918e-04,  1.3959e-03, -2.4451e-03,\n",
      "         5.3974e-04,  5.5970e-04,  3.7949e-03,  1.6524e-04,  2.0960e-03,\n",
      "        -1.1993e-03,  1.1281e-03, -1.3426e-03, -2.0037e-04,  2.7543e-03,\n",
      "         3.2663e-03, -4.0477e-04, -1.7788e-03,  1.3229e-03, -1.6517e-03,\n",
      "         1.7708e-04, -1.5642e-03,  4.3351e-04,  1.8505e-03,  1.6159e-03,\n",
      "        -1.4969e-03, -4.2783e-04, -2.1276e-03, -8.4041e-04, -2.4385e-04,\n",
      "         8.1900e-04, -9.6197e-05, -1.3990e-03,  1.1723e-03,  1.2080e-03,\n",
      "         5.3509e-04, -1.0004e-03, -5.0227e-05,  1.0268e-03, -1.2144e-03,\n",
      "         5.7374e-05,  2.8667e-04, -1.4859e-03, -1.1579e-03,  1.0459e-03,\n",
      "        -9.0233e-04,  1.1421e-03,  1.7766e-04,  7.4977e-04, -2.2693e-04,\n",
      "        -1.0315e-03, -3.5302e-04, -7.7516e-04, -3.8577e-04, -1.2192e-03,\n",
      "        -1.0361e-03,  8.9875e-05,  1.2901e-03, -1.1070e-03, -1.5499e-04,\n",
      "        -5.3625e-04, -2.9079e-05,  1.4637e-03,  9.4933e-05,  1.5875e-03,\n",
      "        -6.1593e-04, -6.5579e-04, -1.8236e-03,  1.1977e-04, -4.7638e-04,\n",
      "        -2.9609e-04,  8.4725e-04, -1.1241e-03,  7.9958e-04, -7.2140e-04,\n",
      "        -5.6659e-04, -9.2508e-04, -6.7172e-04,  1.2566e-03,  1.3419e-03,\n",
      "         7.8374e-04,  7.6306e-04, -2.1611e-04,  3.1623e-04,  2.0187e-03,\n",
      "         2.2950e-04, -4.6514e-04, -8.7921e-04, -3.2991e-04,  9.5332e-04,\n",
      "         3.3855e-04, -7.0178e-04,  1.0390e-03, -4.7458e-04, -3.4770e-03,\n",
      "         5.5972e-04,  1.3018e-03, -5.5704e-04,  1.5175e-03,  4.7944e-04,\n",
      "         2.0271e-04,  2.4413e-03,  9.3645e-04, -5.9483e-04,  4.8584e-04,\n",
      "         4.0461e-04,  2.6072e-04,  2.2945e-04,  5.1710e-05, -1.4087e-04,\n",
      "         4.6546e-04, -4.8535e-04,  5.1419e-04,  1.1709e-04, -1.2566e-03,\n",
      "         1.4400e-03,  6.1960e-04,  9.3449e-04, -1.1102e-04, -1.1432e-03,\n",
      "         6.0139e-04, -1.6973e-03, -7.7874e-04, -4.7527e-04, -6.3743e-04,\n",
      "         3.6100e-04,  7.7094e-04,  6.4131e-04,  1.7636e-04, -1.6330e-04,\n",
      "        -1.7230e-03,  2.1069e-03,  3.4742e-04, -1.2877e-03, -3.4644e-04,\n",
      "         3.4179e-04, -8.3430e-04,  1.2965e-03, -7.2630e-04,  1.5172e-03,\n",
      "         2.0063e-03, -4.3604e-04, -1.0985e-03,  5.4311e-04,  1.6151e-03,\n",
      "         4.0679e-04, -4.4237e-04,  1.6472e-03,  4.5663e-05,  7.7397e-05,\n",
      "        -1.0233e-04,  1.0587e-03,  3.3133e-03, -7.6854e-05,  1.4754e-03,\n",
      "        -2.0803e-03, -8.2583e-04, -1.8552e-04, -1.1371e-03, -1.2123e-03,\n",
      "        -6.4018e-04, -1.0569e-03, -7.9061e-04, -3.7893e-04,  4.4368e-04,\n",
      "        -1.8340e-05,  2.2655e-03, -5.0853e-04,  1.5860e-03,  7.2200e-05,\n",
      "         3.1475e-03,  1.6376e-03,  1.9312e-03,  9.0020e-04,  1.1876e-03,\n",
      "         1.9550e-05, -1.7119e-04,  2.3845e-03, -2.4601e-04, -1.9082e-03,\n",
      "         3.5950e-03,  6.9622e-04,  1.2002e-03, -1.6229e-03, -1.9795e-04,\n",
      "         2.4816e-03,  1.5426e-03, -1.3781e-04, -8.4533e-04, -2.8829e-04,\n",
      "         9.9983e-04,  7.6415e-04, -1.6537e-03, -6.2661e-04, -1.3411e-03,\n",
      "         3.0333e-03,  1.0917e-04,  3.8916e-04, -5.9785e-04, -1.7263e-03,\n",
      "         1.1995e-03, -1.9602e-03,  2.3476e-03, -1.9018e-03, -3.6302e-04,\n",
      "         3.6431e-04,  9.1112e-04,  9.6077e-04,  1.1092e-03, -2.4813e-03,\n",
      "         5.2599e-04, -1.0351e-03, -2.1865e-03,  2.0699e-04,  3.0891e-04,\n",
      "        -1.5224e-03,  1.7668e-03, -1.1996e-03], requires_grad=True)), ('weight_orig', Parameter containing:\n",
      "tensor([[ 2.8657e-02, -3.0682e-02, -2.6921e-03,  ...,  2.3738e-02,\n",
      "         -7.9208e-03, -1.0336e-02],\n",
      "        [ 4.8005e-03, -3.0306e-03,  2.4164e-02,  ...,  7.4704e-03,\n",
      "          4.4420e-02,  2.5629e-02],\n",
      "        [ 4.9076e-02, -1.2873e-02, -1.3648e-02,  ...,  3.8690e-02,\n",
      "          1.6604e-02,  7.9800e-05],\n",
      "        ...,\n",
      "        [-8.8108e-03, -3.2314e-03,  1.1721e-02,  ..., -2.8807e-02,\n",
      "          4.6374e-03,  3.5982e-02],\n",
      "        [ 5.6885e-03,  5.2938e-02,  9.4898e-03,  ...,  5.6113e-02,\n",
      "          2.6797e-02,  4.9962e-02],\n",
      "        [ 5.4869e-02, -3.6515e-03,  1.5125e-02,  ..., -2.0291e-02,\n",
      "         -2.8913e-03,  1.4802e-02]], requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "module = model.encoder.layer[0].attention.self.key\n",
    "prune.random_unstructured(module, name=\"weight\", amount=0.3)\n",
    "\n",
    "print(list(module.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 606,
     "status": "ok",
     "timestamp": 1587921575099,
     "user": {
      "displayName": "Seoyoung Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjITIRuMxnapYLrcCepnJsCF3Rb52KogXDd9B-Mhg=s64",
      "userId": "04592586031163595245"
     },
     "user_tz": -540
    },
    "id": "_7UuFO-Camaf",
    "outputId": "ab4881c9-0135-499d-c0ce-752cd9be482b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('weight_mask', tensor([[1., 1., 1.,  ..., 0., 1., 1.],\n",
      "        [0., 1., 0.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 0.,  ..., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 1., 1.,  ..., 0., 1., 1.],\n",
      "        [1., 1., 0.,  ..., 1., 1., 1.],\n",
      "        [1., 0., 1.,  ..., 1., 1., 1.]]))]\n"
     ]
    }
   ],
   "source": [
    "print(list(module.named_buffers()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 561,
     "status": "ok",
     "timestamp": 1587921577969,
     "user": {
      "displayName": "Seoyoung Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjITIRuMxnapYLrcCepnJsCF3Rb52KogXDd9B-Mhg=s64",
      "userId": "04592586031163595245"
     },
     "user_tz": -540
    },
    "id": "_KkpF1Y3ani3",
    "outputId": "e7144e37-3ccc-4b86-eb46-cdfee1cc5825"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('weight_mask', tensor([[0., 0., 1.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 1., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 1., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 1.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 1., 0., 1.],\n",
      "        [0., 0., 1.,  ..., 1., 0., 1.]]))]\n"
     ]
    }
   ],
   "source": [
    "prune.ln_structured(module, name='weight', amount=0.3, n=2, dim=1)\n",
    "print(list(module.named_buffers()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 647,
     "status": "ok",
     "timestamp": 1587921585331,
     "user": {
      "displayName": "Seoyoung Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjITIRuMxnapYLrcCepnJsCF3Rb52KogXDd9B-Mhg=s64",
      "userId": "04592586031163595245"
     },
     "user_tz": -540
    },
    "id": "KH-4XoP2a1pv",
    "outputId": "3f9f212c-c382-445b-c881-eb30ece167e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bias', Parameter containing:\n",
      "tensor([-4.5075e-04,  6.3931e-04, -1.3673e-04, -4.4833e-04, -4.8297e-04,\n",
      "         8.5335e-04, -6.2471e-04,  7.7209e-04, -4.6402e-04,  4.8441e-04,\n",
      "         9.7060e-05, -7.4744e-04, -1.4687e-03, -3.6819e-04, -4.6814e-04,\n",
      "         9.9541e-04, -3.0008e-03, -1.0790e-03, -1.6073e-04, -4.6535e-04,\n",
      "         5.6987e-04, -1.8128e-03,  2.0990e-03, -3.5929e-05,  2.1796e-04,\n",
      "         2.0506e-03, -8.8005e-04,  4.4442e-04,  6.4584e-04, -1.9093e-03,\n",
      "         4.4126e-04,  2.0759e-04, -1.5373e-04, -1.5536e-04,  3.5340e-05,\n",
      "        -4.4808e-04,  1.3942e-03,  5.9183e-04, -1.4158e-05,  8.4992e-04,\n",
      "        -7.8199e-04,  2.6565e-04, -1.9708e-03, -8.8281e-04, -9.4142e-04,\n",
      "        -1.0624e-04, -2.1437e-03,  1.9360e-04, -1.1071e-03, -6.4646e-04,\n",
      "         5.0200e-04, -7.7265e-04, -3.2641e-04,  3.1411e-05, -1.2639e-03,\n",
      "         4.9262e-04,  3.7519e-04, -5.6525e-05, -6.5781e-04,  4.6099e-04,\n",
      "        -2.4043e-03,  7.3155e-04, -1.6624e-03,  4.1991e-04,  5.2776e-06,\n",
      "        -1.9378e-03,  3.0003e-03, -8.9278e-04,  4.3344e-05,  2.5033e-03,\n",
      "        -6.4651e-04,  1.2104e-03, -1.0243e-03, -1.2653e-03, -5.8322e-04,\n",
      "        -1.2446e-03, -8.7324e-04,  1.5257e-04, -1.6892e-03, -2.2702e-04,\n",
      "         4.7292e-04, -1.9658e-03, -1.2071e-03, -1.1187e-03, -1.2895e-03,\n",
      "        -9.3685e-04,  1.3970e-03,  5.4844e-04, -1.3878e-03,  6.6890e-06,\n",
      "        -1.8691e-03, -9.3432e-04,  4.6209e-04,  3.1122e-04, -4.4163e-05,\n",
      "         1.7544e-03, -2.3810e-04, -2.5493e-03, -6.6575e-04,  5.4853e-04,\n",
      "        -2.4245e-03, -7.5354e-04, -2.0370e-03,  2.3277e-04,  3.4582e-03,\n",
      "         1.3604e-03,  1.2960e-03,  4.5274e-03, -1.0648e-03,  1.1124e-03,\n",
      "         1.5280e-03,  6.8583e-04, -3.5745e-04, -1.2804e-03, -4.6646e-04,\n",
      "         1.4927e-03, -7.9551e-04,  1.4773e-03, -7.8367e-04, -3.2938e-04,\n",
      "        -2.3481e-03,  1.6548e-04,  1.6505e-03, -1.1459e-03,  1.3988e-03,\n",
      "         1.5846e-03, -1.8112e-03,  2.6534e-03,  8.5451e-04, -1.8381e-04,\n",
      "        -2.9746e-04,  2.0692e-04,  9.4245e-05, -1.3992e-03,  1.1498e-04,\n",
      "        -4.6970e-04, -1.1821e-03, -2.2678e-03, -5.3473e-04,  2.3039e-04,\n",
      "         1.1064e-03, -6.4366e-04, -1.2395e-03, -2.9480e-05, -1.2138e-03,\n",
      "         4.0610e-04, -6.9925e-04,  5.4872e-04,  6.1843e-04,  9.3020e-04,\n",
      "         4.3791e-04, -8.8416e-05,  1.5406e-04,  9.0997e-04, -2.4790e-04,\n",
      "        -1.2500e-03,  1.9390e-04,  5.3811e-04, -8.8558e-04,  8.3321e-04,\n",
      "        -1.0934e-03,  5.1671e-04, -5.3213e-04, -1.5079e-03,  9.7987e-04,\n",
      "        -1.9925e-03, -5.9103e-04, -1.1471e-03, -1.3482e-03,  4.1966e-06,\n",
      "        -6.0771e-04,  6.7213e-04,  5.7242e-04,  1.4748e-04,  6.7059e-04,\n",
      "        -2.5242e-04, -1.2935e-03, -2.7342e-04, -3.1357e-03, -1.3709e-04,\n",
      "         8.4321e-06, -6.1891e-04, -4.6440e-04, -3.3269e-04, -1.0687e-03,\n",
      "        -7.0425e-04, -1.1379e-03, -5.8975e-04, -4.1942e-04, -8.9134e-04,\n",
      "         3.6225e-04,  1.2173e-03,  1.1709e-03,  1.0337e-03,  2.0972e-03,\n",
      "         4.6325e-03,  9.1117e-04,  7.0136e-03,  3.9219e-03, -9.6026e-04,\n",
      "        -7.1620e-03,  3.2062e-03, -2.2073e-03,  3.4789e-03, -8.8383e-04,\n",
      "        -5.5295e-04,  4.5864e-04, -2.4891e-03, -2.9448e-03, -2.6067e-03,\n",
      "        -3.1958e-03, -3.4512e-03,  2.4487e-03,  3.1093e-03,  1.4709e-03,\n",
      "        -1.0581e-03,  2.2739e-03, -5.8854e-03,  3.0629e-03,  2.3796e-04,\n",
      "        -1.7535e-03,  3.3720e-03, -1.0200e-03, -1.1698e-03,  2.8293e-03,\n",
      "         2.3649e-03,  3.9963e-03, -3.2470e-03, -7.0003e-03,  2.9345e-04,\n",
      "        -4.2233e-03,  3.7131e-04, -1.5399e-03, -4.4571e-04,  3.7502e-03,\n",
      "         7.2077e-03, -3.5842e-03,  3.5463e-03, -3.0626e-03,  3.4716e-03,\n",
      "        -9.8799e-04,  1.5825e-03,  1.7237e-03,  3.5100e-03, -3.2561e-04,\n",
      "         1.8846e-03,  7.2731e-03,  1.0541e-03, -4.7822e-03, -1.8538e-03,\n",
      "        -1.2346e-03, -2.4767e-04, -2.3871e-03,  2.2927e-03,  2.3214e-04,\n",
      "        -8.5822e-04,  2.8567e-03,  1.5331e-03, -1.0209e-04, -9.4502e-05,\n",
      "        -1.8115e-03,  9.8671e-04, -4.1052e-04, -2.8865e-03, -1.1590e-04,\n",
      "         4.4826e-04,  7.4345e-05, -4.4182e-04,  2.2170e-04, -2.6022e-03,\n",
      "         8.9430e-04,  4.0814e-03, -1.7227e-03, -1.6447e-03,  6.3763e-04,\n",
      "         7.9844e-04, -2.5195e-04, -2.8073e-04,  1.3934e-03,  8.8477e-04,\n",
      "         2.4402e-03,  2.6572e-03, -3.8261e-04, -3.5675e-03,  3.9919e-03,\n",
      "        -4.1065e-04,  1.6129e-03, -3.6500e-04, -5.0602e-04, -2.9292e-03,\n",
      "        -1.4711e-03, -2.2187e-03, -2.6717e-04, -2.0390e-03,  6.6572e-04,\n",
      "        -1.5454e-03, -2.0897e-04, -3.1104e-04, -9.1675e-05,  9.7432e-04,\n",
      "        -1.7890e-04,  7.0667e-04,  1.0518e-04, -1.1013e-03, -1.2165e-03,\n",
      "         9.5313e-04, -1.2669e-03,  5.0920e-04, -1.5487e-03,  1.0149e-03,\n",
      "        -7.4706e-04,  6.0163e-04, -4.6153e-05, -5.2320e-04, -5.5379e-04,\n",
      "         2.3721e-03, -1.1345e-03, -1.1679e-03, -1.0999e-03,  5.5690e-04,\n",
      "        -1.8064e-03,  5.2338e-04, -8.7620e-04, -1.1788e-03,  3.3634e-03,\n",
      "        -1.2350e-03, -6.2554e-04, -1.0900e-05,  7.3770e-04, -1.6454e-03,\n",
      "        -2.4058e-03, -2.0036e-03, -2.3530e-03, -4.1878e-04, -2.3022e-03,\n",
      "        -2.5860e-03,  9.8766e-04, -9.2863e-04, -7.6622e-04,  1.5469e-03,\n",
      "        -2.2305e-03,  1.0740e-03, -1.9992e-04,  4.2950e-03,  6.1812e-04,\n",
      "        -3.6555e-03, -3.9012e-03, -6.5666e-04, -9.3937e-04, -3.2627e-03,\n",
      "         9.7545e-04, -1.5124e-03, -1.8600e-03, -6.6509e-04,  1.0588e-03,\n",
      "         6.1127e-04,  1.3538e-03,  4.8610e-04, -3.7257e-05, -3.2132e-03,\n",
      "         2.3919e-03,  1.8338e-03,  3.4705e-03, -2.5586e-03,  5.2118e-04,\n",
      "        -2.7088e-03, -8.3863e-04, -1.1010e-03,  2.4027e-03,  1.2161e-03,\n",
      "         6.2238e-04, -3.2530e-03, -2.3460e-04, -1.8522e-05, -1.7832e-03,\n",
      "        -2.8128e-03, -4.2183e-04, -1.3625e-03,  1.0366e-03,  7.0225e-04,\n",
      "        -1.1659e-03,  6.2746e-05,  1.6689e-03,  3.4855e-04, -1.1422e-03,\n",
      "         9.1986e-04, -1.7182e-03, -7.6924e-04, -1.1435e-03,  1.7655e-03,\n",
      "         1.1915e-03,  1.1780e-03,  3.0245e-04, -1.4028e-04, -3.0104e-03,\n",
      "         2.3982e-03, -1.7224e-03,  7.0373e-04,  3.9824e-03, -1.6743e-04,\n",
      "        -9.7077e-04,  1.2812e-03, -1.1822e-04,  1.9302e-03,  1.3302e-03,\n",
      "         6.8155e-05, -2.3481e-03,  1.3737e-03,  1.6056e-04,  9.8859e-05,\n",
      "         5.8619e-04,  3.3607e-04,  9.9278e-04, -2.0128e-03,  1.0509e-03,\n",
      "         2.6307e-03,  6.9428e-04,  5.7091e-04, -6.7450e-04,  4.7832e-04,\n",
      "         1.3574e-03, -1.6465e-03, -4.5223e-04,  2.8580e-03,  1.5665e-03,\n",
      "        -2.7018e-04, -2.8117e-03, -3.6844e-03,  8.5407e-04, -3.4515e-03,\n",
      "         5.6900e-04, -7.8704e-04,  9.3086e-04,  1.6276e-03,  6.6189e-04,\n",
      "        -1.3816e-03,  8.7184e-04,  2.9130e-03, -6.6432e-04, -3.0845e-03,\n",
      "        -1.0382e-03, -8.2503e-04,  7.9967e-04, -2.7094e-04,  8.6063e-06,\n",
      "        -1.4261e-03,  1.4532e-03,  9.1169e-04,  1.9083e-04, -3.1608e-04,\n",
      "        -1.1374e-04, -2.5696e-05, -7.9211e-04, -1.2628e-03,  1.2918e-03,\n",
      "         6.2048e-04, -5.8662e-04,  1.2440e-03,  1.1432e-03, -3.3663e-04,\n",
      "         9.8559e-04,  7.5414e-04, -2.1163e-03, -2.3401e-04,  4.1029e-04,\n",
      "        -1.5389e-04, -2.1303e-04,  8.0477e-05,  1.5120e-04, -9.6375e-04,\n",
      "         6.6871e-04, -8.4291e-04, -2.0257e-04,  3.6672e-05,  4.2345e-04,\n",
      "         5.5477e-04,  8.9161e-04, -1.3884e-03, -7.9123e-04, -6.9587e-04,\n",
      "        -3.7094e-04, -1.1370e-03,  2.4306e-04, -3.6434e-04, -4.2379e-04,\n",
      "        -1.8570e-04, -1.0734e-04, -9.2729e-06, -3.7936e-04,  2.7610e-04,\n",
      "        -2.2923e-03, -1.3877e-04, -3.6226e-04,  4.3790e-05, -8.1488e-05,\n",
      "        -7.0583e-04,  3.8284e-04, -6.4710e-04,  3.5178e-04, -5.3818e-04,\n",
      "         1.2480e-03,  5.0027e-04, -4.4209e-04,  5.9019e-04,  7.3998e-04,\n",
      "        -3.2291e-04,  8.1916e-05,  4.5663e-04,  8.0259e-04,  1.6296e-03,\n",
      "        -2.8502e-04,  3.4830e-04, -2.8572e-05,  6.9768e-04,  1.1212e-03,\n",
      "         1.5246e-03,  4.7797e-04, -2.0629e-03, -1.8813e-03,  3.4155e-03,\n",
      "        -1.3322e-03,  2.1190e-04,  1.9147e-04, -4.7127e-04, -6.0859e-04,\n",
      "         1.8072e-03,  5.5468e-04, -1.9804e-03,  1.5034e-03, -4.7569e-04,\n",
      "        -1.2072e-03, -1.3745e-03, -1.0465e-03, -3.8901e-04, -2.6570e-04,\n",
      "         8.0261e-04,  1.5594e-03,  6.9251e-04, -7.4193e-05, -6.0562e-04,\n",
      "         1.1299e-03,  2.3621e-04,  1.0665e-03, -7.1161e-04,  3.1995e-03,\n",
      "         2.1107e-03,  5.9163e-05, -2.9844e-04, -1.3449e-03, -2.0177e-04,\n",
      "         1.3499e-03, -1.7493e-03,  5.1918e-04,  1.3959e-03, -2.4451e-03,\n",
      "         5.3974e-04,  5.5970e-04,  3.7949e-03,  1.6524e-04,  2.0960e-03,\n",
      "        -1.1993e-03,  1.1281e-03, -1.3426e-03, -2.0037e-04,  2.7543e-03,\n",
      "         3.2663e-03, -4.0477e-04, -1.7788e-03,  1.3229e-03, -1.6517e-03,\n",
      "         1.7708e-04, -1.5642e-03,  4.3351e-04,  1.8505e-03,  1.6159e-03,\n",
      "        -1.4969e-03, -4.2783e-04, -2.1276e-03, -8.4041e-04, -2.4385e-04,\n",
      "         8.1900e-04, -9.6197e-05, -1.3990e-03,  1.1723e-03,  1.2080e-03,\n",
      "         5.3509e-04, -1.0004e-03, -5.0227e-05,  1.0268e-03, -1.2144e-03,\n",
      "         5.7374e-05,  2.8667e-04, -1.4859e-03, -1.1579e-03,  1.0459e-03,\n",
      "        -9.0233e-04,  1.1421e-03,  1.7766e-04,  7.4977e-04, -2.2693e-04,\n",
      "        -1.0315e-03, -3.5302e-04, -7.7516e-04, -3.8577e-04, -1.2192e-03,\n",
      "        -1.0361e-03,  8.9875e-05,  1.2901e-03, -1.1070e-03, -1.5499e-04,\n",
      "        -5.3625e-04, -2.9079e-05,  1.4637e-03,  9.4933e-05,  1.5875e-03,\n",
      "        -6.1593e-04, -6.5579e-04, -1.8236e-03,  1.1977e-04, -4.7638e-04,\n",
      "        -2.9609e-04,  8.4725e-04, -1.1241e-03,  7.9958e-04, -7.2140e-04,\n",
      "        -5.6659e-04, -9.2508e-04, -6.7172e-04,  1.2566e-03,  1.3419e-03,\n",
      "         7.8374e-04,  7.6306e-04, -2.1611e-04,  3.1623e-04,  2.0187e-03,\n",
      "         2.2950e-04, -4.6514e-04, -8.7921e-04, -3.2991e-04,  9.5332e-04,\n",
      "         3.3855e-04, -7.0178e-04,  1.0390e-03, -4.7458e-04, -3.4770e-03,\n",
      "         5.5972e-04,  1.3018e-03, -5.5704e-04,  1.5175e-03,  4.7944e-04,\n",
      "         2.0271e-04,  2.4413e-03,  9.3645e-04, -5.9483e-04,  4.8584e-04,\n",
      "         4.0461e-04,  2.6072e-04,  2.2945e-04,  5.1710e-05, -1.4087e-04,\n",
      "         4.6546e-04, -4.8535e-04,  5.1419e-04,  1.1709e-04, -1.2566e-03,\n",
      "         1.4400e-03,  6.1960e-04,  9.3449e-04, -1.1102e-04, -1.1432e-03,\n",
      "         6.0139e-04, -1.6973e-03, -7.7874e-04, -4.7527e-04, -6.3743e-04,\n",
      "         3.6100e-04,  7.7094e-04,  6.4131e-04,  1.7636e-04, -1.6330e-04,\n",
      "        -1.7230e-03,  2.1069e-03,  3.4742e-04, -1.2877e-03, -3.4644e-04,\n",
      "         3.4179e-04, -8.3430e-04,  1.2965e-03, -7.2630e-04,  1.5172e-03,\n",
      "         2.0063e-03, -4.3604e-04, -1.0985e-03,  5.4311e-04,  1.6151e-03,\n",
      "         4.0679e-04, -4.4237e-04,  1.6472e-03,  4.5663e-05,  7.7397e-05,\n",
      "        -1.0233e-04,  1.0587e-03,  3.3133e-03, -7.6854e-05,  1.4754e-03,\n",
      "        -2.0803e-03, -8.2583e-04, -1.8552e-04, -1.1371e-03, -1.2123e-03,\n",
      "        -6.4018e-04, -1.0569e-03, -7.9061e-04, -3.7893e-04,  4.4368e-04,\n",
      "        -1.8340e-05,  2.2655e-03, -5.0853e-04,  1.5860e-03,  7.2200e-05,\n",
      "         3.1475e-03,  1.6376e-03,  1.9312e-03,  9.0020e-04,  1.1876e-03,\n",
      "         1.9550e-05, -1.7119e-04,  2.3845e-03, -2.4601e-04, -1.9082e-03,\n",
      "         3.5950e-03,  6.9622e-04,  1.2002e-03, -1.6229e-03, -1.9795e-04,\n",
      "         2.4816e-03,  1.5426e-03, -1.3781e-04, -8.4533e-04, -2.8829e-04,\n",
      "         9.9983e-04,  7.6415e-04, -1.6537e-03, -6.2661e-04, -1.3411e-03,\n",
      "         3.0333e-03,  1.0917e-04,  3.8916e-04, -5.9785e-04, -1.7263e-03,\n",
      "         1.1995e-03, -1.9602e-03,  2.3476e-03, -1.9018e-03, -3.6302e-04,\n",
      "         3.6431e-04,  9.1112e-04,  9.6077e-04,  1.1092e-03, -2.4813e-03,\n",
      "         5.2599e-04, -1.0351e-03, -2.1865e-03,  2.0699e-04,  3.0891e-04,\n",
      "        -1.5224e-03,  1.7668e-03, -1.1996e-03], requires_grad=True)), ('weight', Parameter containing:\n",
      "tensor([[ 0.0000e+00, -0.0000e+00, -2.6921e-03,  ...,  0.0000e+00,\n",
      "         -0.0000e+00, -1.0336e-02],\n",
      "        [ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ...,  7.4704e-03,\n",
      "          0.0000e+00,  2.5629e-02],\n",
      "        [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  3.8690e-02,\n",
      "          0.0000e+00,  7.9800e-05],\n",
      "        ...,\n",
      "        [-0.0000e+00, -0.0000e+00,  1.1721e-02,  ..., -0.0000e+00,\n",
      "          0.0000e+00,  3.5982e-02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  5.6113e-02,\n",
      "          0.0000e+00,  4.9962e-02],\n",
      "        [ 0.0000e+00, -0.0000e+00,  1.5125e-02,  ..., -2.0291e-02,\n",
      "         -0.0000e+00,  1.4802e-02]], requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "prune.remove(module, 'weight')\n",
    "print(list(module.named_parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gt6ZEy5Zcgec"
   },
   "source": [
    "# Global Pruning\n",
    "> 모델 전체에 Pruning을 한 번에 적용하는 글로벌 Pruning\n",
    "\n",
    "모델 전체에 글로벌 Pruning을 적용하게 되면 앞선 예제들에서처럼 개별 텐서에서 영향력이 작은 파라미터를 가지치기 하는 것이 아닌, 모듈 간 연결에 있어 영향력이 작은 파라미터들이 가지치기 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UIi8u6mka9uz"
   },
   "outputs": [],
   "source": [
    "final_model = BertModel.from_pretrained('bert-base-cased')\n",
    "\n",
    "parameters_to_prune = ()\n",
    "for i in range(12):\n",
    "    parameters_to_prune += (\n",
    "        (final_model.encoder.layer[i].attention.self.key, 'weight'),\n",
    "        (final_model.encoder.layer[i].attention.self.query, 'weight'),\n",
    "        (final_model.encoder.layer[i].attention.self.value, 'weight'),\n",
    "    )\n",
    "\n",
    "prune.global_unstructured(\n",
    "    parameters_to_prune,\n",
    "    pruning_method=prune.L1Unstructured,\n",
    "    amount=0.3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 823
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 526,
     "status": "ok",
     "timestamp": 1587921636411,
     "user": {
      "displayName": "Seoyoung Hong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjITIRuMxnapYLrcCepnJsCF3Rb52KogXDd9B-Mhg=s64",
      "userId": "04592586031163595245"
     },
     "user_tz": -540
    },
    "id": "bjSIF7ngba31",
    "outputId": "5de41d49-da8d-4b95-d38e-20d02c185728"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity in Layer 1-th key weight: 32.36%\n",
      "Sparsity in Layer 1-th query weightt: 31.65%\n",
      "Sparsity in Layer 1-th value weight: 42.49%\n",
      "\n",
      "Sparsity in Layer 2-th key weight: 29.24%\n",
      "Sparsity in Layer 2-th query weightt: 28.94%\n",
      "Sparsity in Layer 2-th value weight: 40.62%\n",
      "\n",
      "Sparsity in Layer 3-th key weight: 28.07%\n",
      "Sparsity in Layer 3-th query weightt: 27.63%\n",
      "Sparsity in Layer 3-th value weight: 39.12%\n",
      "\n",
      "Sparsity in Layer 4-th key weight: 27.86%\n",
      "Sparsity in Layer 4-th query weightt: 27.64%\n",
      "Sparsity in Layer 4-th value weight: 37.69%\n",
      "\n",
      "Sparsity in Layer 5-th key weight: 27.51%\n",
      "Sparsity in Layer 5-th query weightt: 27.32%\n",
      "Sparsity in Layer 5-th value weight: 33.67%\n",
      "\n",
      "Sparsity in Layer 6-th key weight: 25.86%\n",
      "Sparsity in Layer 6-th query weightt: 25.58%\n",
      "Sparsity in Layer 6-th value weight: 35.85%\n",
      "\n",
      "Sparsity in Layer 7-th key weight: 25.83%\n",
      "Sparsity in Layer 7-th query weightt: 25.23%\n",
      "Sparsity in Layer 7-th value weight: 36.38%\n",
      "\n",
      "Sparsity in Layer 8-th key weight: 26.26%\n",
      "Sparsity in Layer 8-th query weightt: 26.01%\n",
      "Sparsity in Layer 8-th value weight: 34.46%\n",
      "\n",
      "Sparsity in Layer 9-th key weight: 26.29%\n",
      "Sparsity in Layer 9-th query weightt: 26.15%\n",
      "Sparsity in Layer 9-th value weight: 33.51%\n",
      "\n",
      "Sparsity in Layer 10-th key weight: 26.25%\n",
      "Sparsity in Layer 10-th query weightt: 26.05%\n",
      "Sparsity in Layer 10-th value weight: 33.91%\n",
      "\n",
      "Sparsity in Layer 11-th key weight: 25.34%\n",
      "Sparsity in Layer 11-th query weightt: 25.15%\n",
      "Sparsity in Layer 11-th value weight: 34.22%\n",
      "\n",
      "Sparsity in Layer 12-th key weight: 25.90%\n",
      "Sparsity in Layer 12-th query weightt: 25.68%\n",
      "Sparsity in Layer 12-th value weight: 28.28%\n",
      "\n",
      "Global sparsity: 30.00%\n"
     ]
    }
   ],
   "source": [
    "for i in range(12):\n",
    "    print(\n",
    "        \"Sparsity in Layer {}-th key weight: {:.2f}%\".format(\n",
    "            i+1,\n",
    "            100. * float(torch.sum(final_model.encoder.layer[i].attention.self.key.weight == 0))\n",
    "            / float(final_model.encoder.layer[i].attention.self.key.weight.nelement())\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        \"Sparsity in Layer {}-th query weightt: {:.2f}%\".format(\n",
    "            i+1,\n",
    "            100. * float(torch.sum(final_model.encoder.layer[i].attention.self.query.weight == 0))\n",
    "            / float(final_model.encoder.layer[i].attention.self.query.weight.nelement())\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        \"Sparsity in Layer {}-th value weight: {:.2f}%\".format(\n",
    "            i+1,\n",
    "            100. * float(torch.sum(final_model.encoder.layer[i].attention.self.value.weight == 0))\n",
    "            / float(final_model.encoder.layer[i].attention.self.value.weight.nelement())\n",
    "        )\n",
    "    )\n",
    "    print()\n",
    "\n",
    "    \n",
    "numerator, denominator = 0, 0\n",
    "for i in range(12):\n",
    "    numerator += torch.sum(final_model.encoder.layer[i].attention.self.key.weight == 0)\n",
    "    numerator += torch.sum(final_model.encoder.layer[i].attention.self.query.weight == 0)\n",
    "    numerator += torch.sum(final_model.encoder.layer[i].attention.self.value.weight == 0)\n",
    "\n",
    "    denominator += final_model.encoder.layer[i].attention.self.key.weight.nelement()\n",
    "    denominator += final_model.encoder.layer[i].attention.self.query.weight.nelement()\n",
    "    denominator += final_model.encoder.layer[i].attention.self.value.weight.nelement()\n",
    "    \n",
    "print(\"Global sparsity: {:.2f}%\".format(100. * float(numerator) / float(denominator)))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "authorship_tag": "ABX9TyMIlsTl1BJRjTwPXMv4GTBN",
   "collapsed_sections": [],
   "name": "testing_bert_pruning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1de7303e02da4b4f9f0c33b7694c1699": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1ff8111a0070443baa6d77f3b1d941b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c926e1a523534ee285b8cd14bf1820ae",
      "max": 435779157,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_98f5c2cd419340daba80571e7a05b1df",
      "value": 435779157
     }
    },
    "20b9698fc2664b0aa133339d293fb4dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e249900b5a534ba6a6ce0ec666f2eaad",
       "IPY_MODEL_6bdb804980d949e3852d675e9cfbfd2b"
      ],
      "layout": "IPY_MODEL_bf2e5a40256c41cdaabb73aa16f4a7da"
     }
    },
    "55eec29e4bcd4cbc8d3449957cba4e4a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6bdb804980d949e3852d675e9cfbfd2b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a33b2f80b4e24f26a188ad1a604207d5",
      "placeholder": "​",
      "style": "IPY_MODEL_1de7303e02da4b4f9f0c33b7694c1699",
      "value": " 433/433 [00:00&lt;00:00, 15.8kB/s]"
     }
    },
    "6bee764c91e24a81a47fd02048016b01": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d6ebd505ebbc4735a5cca84d338e7629",
      "placeholder": "​",
      "style": "IPY_MODEL_b1ec5e075fdf41dd9e8236d17f684e39",
      "value": " 436M/436M [00:46&lt;00:00, 9.30MB/s]"
     }
    },
    "98f5c2cd419340daba80571e7a05b1df": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "a33b2f80b4e24f26a188ad1a604207d5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b1ec5e075fdf41dd9e8236d17f684e39": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bce0a4a3a6fa4920a22f288e3e1c8ddc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1ff8111a0070443baa6d77f3b1d941b5",
       "IPY_MODEL_6bee764c91e24a81a47fd02048016b01"
      ],
      "layout": "IPY_MODEL_d140d44d67214c809ce2db1b7007a5b9"
     }
    },
    "bf2e5a40256c41cdaabb73aa16f4a7da": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c926e1a523534ee285b8cd14bf1820ae": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cefb6c6667084eadb59730b3eea854fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "d140d44d67214c809ce2db1b7007a5b9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d6ebd505ebbc4735a5cca84d338e7629": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e249900b5a534ba6a6ce0ec666f2eaad": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_55eec29e4bcd4cbc8d3449957cba4e4a",
      "max": 433,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cefb6c6667084eadb59730b3eea854fd",
      "value": 433
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
