{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AG-news.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"CJ92D2O6Jqkn","colab_type":"code","outputId":"8753f3e3-7167-46c1-e39d-f3fa87049462","executionInfo":{"status":"ok","timestamp":1588502396063,"user_tz":-540,"elapsed":19313,"user":{"displayName":"‍홍서영[학생](경영대학 경영학과)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiIddZ52JepimokQVw6hJ6jkjyxEwfdpS2JIyj5=s64","userId":"07488608218318880996"}},"colab":{"base_uri":"https://localhost:8080/","height":118}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UrbKXIUGWS3R","colab_type":"code","colab":{}},"source":["import torch"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mVTivRv2xPpU","colab_type":"code","outputId":"bda8174d-379d-4b79-d34e-464e5c276b1c","executionInfo":{"status":"ok","timestamp":1588502404813,"user_tz":-540,"elapsed":1943,"user":{"displayName":"‍홍서영[학생](경영대학 경영학과)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiIddZ52JepimokQVw6hJ6jkjyxEwfdpS2JIyj5=s64","userId":"07488608218318880996"}},"colab":{"base_uri":"https://localhost:8080/","height":65}},"source":["# GPU Check\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print ('Available devices ', torch.cuda.device_count())\n","print ('Current cuda device ', torch.cuda.current_device())\n","print(torch.cuda.get_device_name(device))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Available devices  1\n","Current cuda device  0\n","Tesla K80\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OU8OIZFNxM5w","colab_type":"code","colab":{}},"source":["# TPU Check\n","\n","assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n","TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n","print('TPU address is', TPU_ADDRESS)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ahzAasAIKtAn","colab_type":"code","colab":{}},"source":["import os\n","import time\n","import torch\n","import torchtext\n","from torchtext import data\n","from torchtext import datasets\n","from torchtext.vocab import GloVe\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","import torch.optim as optim\n","import numpy as np\n","import pandas as pd"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"c86bvB2xLpYQ","colab_type":"code","colab":{}},"source":["import random\n","\n","SEED = 1234 # Random Seed for reproductivity\n","\n","torch.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True\n","\n","TEXT = data.Field(tokenize = 'spacy')\n","LABEL = data.LabelField()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3f5TLnFur9jh","colab_type":"text"},"source":["## AG_news\n","\n","The AG's news topic classification dataset is constructed by choosing 4 largest classes from the original corpus. Each class contains 30,000 training samples and 1,900 testing samples. The total number of training samples is 120,000 and testing 7,600.\n","\n","label\n","1: World\n","2: Sports\n","3: Business\n","4: Sci/Tech"]},{"cell_type":"code","metadata":{"id":"OrinqBcxpZHX","colab_type":"code","colab":{}},"source":["from torchtext.data import TabularDataset\n","\n","# put the train and text csv to PATH\n","DATA_PATH = '/content/drive/My Drive/lottery-ticket-hypothesis-for-text-classification/data/ag_news_csv/'\n","\n","train = data.TabularDataset(path = DATA_PATH + 'train.csv', format = 'csv', fields = [('text', TEXT), ('label', LABEL)], skip_header = False)\n","test = data.TabularDataset(path = DATA_PATH + 'test.csv', format = 'csv', fields = [('text', TEXT), ('label', LABEL)], skip_header = False)\n","\n","# make splits for data\n","# by default this splits 70:30\n","train, valid = train.split(split_ratio = 0.7, random_state = random.seed(SEED))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9mql-moTOP1I","colab_type":"code","outputId":"82034d72-cc26-4771-dc5b-62eb608bf05a","executionInfo":{"status":"ok","timestamp":1588500372218,"user_tz":-540,"elapsed":1920,"user":{"displayName":"Seoyoung Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjITIRuMxnapYLrcCepnJsCF3Rb52KogXDd9B-Mhg=s64","userId":"04592586031163595245"}},"colab":{"base_uri":"https://localhost:8080/","height":135}},"source":["print(f'Number of training examples: {len(train)}')\n","print(f'Number of training examples: {len(valid)}')\n","print(f'Number of testing examples: {len(test)}')\n","\n","print(vars(train.examples[0]))\n","print(vars(valid.examples[0]))\n","print(vars(test.examples[0]))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Number of training examples: 84000\n","Number of training examples: 36000\n","Number of testing examples: 7600\n","{'text': ['In', '30', 'sorties', 'on', 'Monday', ',', 'U.S.', 'helicopters', 'delivered', 'more', 'than', '60,000', 'pounds', 'of', 'water', ',', 'medical', 'supplies', 'and', 'food', '.'], 'label': '1'}\n","{'text': ['London', '-', 'US', 'sports', 'tycoon', 'Malcolm', 'Glazer', 'was', 'trying', 'to', 'win', 'over', 'Manchester', 'United', '#', '39;s', 'two', 'key', 'Irish', 'shareholders', 'in', 'his', 'bid', 'to', 'buy', 'the', 'English', 'soccer', 'club', ',', 'but', 'had', 'not', 'yet', 'entered', 'serious', 'talks', 'with', 'them', ',', 'sources', 'familiar', 'with', 'the', 'situation', 'said', 'yesterday', '.'], 'label': '2'}\n","{'text': ['Unions', 'representing', 'workers', 'at', 'Turner', '  ', 'Newall', 'say', 'they', 'are', \"'\", 'disappointed', \"'\", 'after', 'talks', 'with', 'stricken', 'parent', 'firm', 'Federal', 'Mogul', '.'], 'label': '3'}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ey2_yG8FMa2E","colab_type":"code","outputId":"9db163d6-563f-4ffd-d72b-91c3ef5ab650","executionInfo":{"status":"ok","timestamp":1588500375901,"user_tz":-540,"elapsed":3152,"user":{"displayName":"Seoyoung Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjITIRuMxnapYLrcCepnJsCF3Rb52KogXDd9B-Mhg=s64","userId":"04592586031163595245"}},"colab":{"base_uri":"https://localhost:8080/","height":65}},"source":["MAX_VOCAB_SIZE = 25_000\n","\n","TEXT.build_vocab(train, \n","                 max_size = MAX_VOCAB_SIZE, \n","                 vectors = \"glove.6B.100d\", \n","                 unk_init = torch.Tensor.normal_)\n","\n","LABEL.build_vocab(train)\n","\n","print (\"Length of Text Vocabulary: \" + str(len(TEXT.vocab)))\n","print (\"Vector size of Text Vocabulary: \", TEXT.vocab.vectors.size())\n","print (\"Label Length: \" + str(len(LABEL.vocab)))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Length of Text Vocabulary: 25002\n","Vector size of Text Vocabulary:  torch.Size([25002, 100])\n","Label Length: 4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yTTgLaZ0-gor","colab_type":"code","outputId":"b08b66f6-0ffd-471e-fd9e-45636184b920","executionInfo":{"status":"ok","timestamp":1588500378599,"user_tz":-540,"elapsed":1029,"user":{"displayName":"Seoyoung Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjITIRuMxnapYLrcCepnJsCF3Rb52KogXDd9B-Mhg=s64","userId":"04592586031163595245"}},"colab":{"base_uri":"https://localhost:8080/","height":32}},"source":["print(LABEL.vocab.stoi)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["defaultdict(<function _default_unk_index at 0x7f1595bc7158>, {'2': 0, '1': 1, '4': 2, '3': 3})\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"r11xVhdyHpAK","colab_type":"code","colab":{}},"source":["BATCH_SIZE = 64\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","train_iter, valid_iter, test_iter = data.BucketIterator.splits(\n","    (train, valid, test), \n","    sort_key = lambda x: x.text,\n","    batch_size = BATCH_SIZE,\n","    device = device)\n","\n","vocab_size = len(TEXT.vocab)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-0nmR30mAzNs","colab_type":"code","outputId":"6a3011e5-3c8d-427a-93d7-af97fdd1b4fa","executionInfo":{"status":"ok","timestamp":1588500383584,"user_tz":-540,"elapsed":1177,"user":{"displayName":"Seoyoung Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjITIRuMxnapYLrcCepnJsCF3Rb52KogXDd9B-Mhg=s64","userId":"04592586031163595245"}},"colab":{"base_uri":"https://localhost:8080/","height":49}},"source":["print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n","print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Unique tokens in TEXT vocabulary: 25002\n","Unique tokens in LABEL vocabulary: 4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iJp9F6p3A3Zi","colab_type":"code","outputId":"0c515ad6-99fa-498b-928c-54e30c222885","executionInfo":{"status":"ok","timestamp":1588500385425,"user_tz":-540,"elapsed":1215,"user":{"displayName":"Seoyoung Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjITIRuMxnapYLrcCepnJsCF3Rb52KogXDd9B-Mhg=s64","userId":"04592586031163595245"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["print(TEXT.vocab.freqs.most_common(20))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[('the', 120892), (',', 100935), ('.', 91944), ('-', 68725), ('to', 66932), ('a', 66171), ('of', 62242), ('in', 53173), ('and', 45921), ('on', 32689), (' ', 30797), ('for', 26032), ('#', 23694), ('that', 18925), ('39;s', 17430), ('The', 16755), ('(', 16543), (')', 16261), ('with', 14892), ('its', 14611)]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"M46pkB5sA6hm","colab_type":"code","outputId":"866da877-c46e-4a38-b802-a5843465dcd0","executionInfo":{"status":"ok","timestamp":1588500386653,"user_tz":-540,"elapsed":771,"user":{"displayName":"Seoyoung Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjITIRuMxnapYLrcCepnJsCF3Rb52KogXDd9B-Mhg=s64","userId":"04592586031163595245"}},"colab":{"base_uri":"https://localhost:8080/","height":49}},"source":["print(TEXT.vocab.itos[:10])\n","print(LABEL.vocab.stoi)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["['<unk>', '<pad>', 'the', ',', '.', '-', 'to', 'a', 'of', 'in']\n","defaultdict(<function _default_unk_index at 0x7f1595bc7158>, {'2': 0, '1': 1, '4': 2, '3': 3})\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1FVqAlbxRm1x","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","from torch.nn import functional as F"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4qR2-QrVpXVE","colab_type":"text"},"source":["# CNN"]},{"cell_type":"code","metadata":{"id":"EZxG1wODmVVU","colab_type":"code","colab":{}},"source":["class CNN(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n","                 dropout, pad_idx):\n","        \n","        super().__init__()\n","        \n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","        \n","        self.convs = nn.ModuleList([\n","                                    nn.Conv2d(in_channels = 1, \n","                                              out_channels = n_filters, \n","                                              kernel_size = (fs, embedding_dim)) \n","                                    for fs in filter_sizes\n","                                    ])\n","        \n","        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n","        \n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, text):\n","        \n","        #text = [sent len, batch size]\n","        \n","        text = text.permute(1, 0)\n","                \n","        #text = [batch size, sent len]\n","        \n","        embedded = self.embedding(text)\n","                \n","        #embedded = [batch size, sent len, emb dim]\n","        \n","        embedded = embedded.unsqueeze(1)\n","        \n","        #embedded = [batch size, 1, sent len, emb dim]\n","        \n","        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n","            \n","        #conv_n = [batch size, n_filters, sent len - filter_sizes[n]]\n","        \n","        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n","        \n","        #pooled_n = [batch size, n_filters]\n","        \n","        cat = self.dropout(torch.cat(pooled, dim = 1))\n","\n","        #cat = [batch size, n_filters * len(filter_sizes)]\n","            \n","        return self.fc(cat)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-QaYgcrrmb0J","colab_type":"code","colab":{}},"source":["INPUT_DIM = len(TEXT.vocab)\n","EMBEDDING_DIM = 100\n","N_FILTERS = 100\n","FILTER_SIZES = [2,3,4]\n","OUTPUT_DIM = len(LABEL.vocab)\n","DROPOUT = 0.5\n","PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n","\n","model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-I9ZXLyVnGP_","colab_type":"code","outputId":"6db6932b-c1f6-4d68-a25b-b010393283af","executionInfo":{"status":"ok","timestamp":1588500394949,"user_tz":-540,"elapsed":963,"user":{"displayName":"Seoyoung Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjITIRuMxnapYLrcCepnJsCF3Rb52KogXDd9B-Mhg=s64","userId":"04592586031163595245"}},"colab":{"base_uri":"https://localhost:8080/","height":32}},"source":["def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f'The model has {count_parameters(model):,} trainable parameters')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["The model has 2,591,704 trainable parameters\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ORwt4hYxnH-e","colab_type":"code","outputId":"aefefc2b-dddc-415c-d951-e61a0bec7d95","executionInfo":{"status":"ok","timestamp":1588500396791,"user_tz":-540,"elapsed":1196,"user":{"displayName":"Seoyoung Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjITIRuMxnapYLrcCepnJsCF3Rb52KogXDd9B-Mhg=s64","userId":"04592586031163595245"}},"colab":{"base_uri":"https://localhost:8080/","height":131}},"source":["pretrained_embeddings = TEXT.vocab.vectors\n","\n","model.embedding.weight.data.copy_(pretrained_embeddings)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-0.1117, -0.4966,  0.1631,  ...,  1.2647, -0.2753, -0.1325],\n","        [-0.8555, -0.7208,  1.3755,  ...,  0.0825, -1.1314,  0.3997],\n","        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n","        ...,\n","        [-0.4598,  1.1272, -1.1509,  ..., -0.6062,  0.1021,  0.8086],\n","        [ 0.1967, -2.3082,  0.2116,  ...,  0.9473,  0.1453, -0.7713],\n","        [ 0.0786,  0.3827, -1.8876,  ..., -0.1305, -0.2890, -0.5978]])"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"lhYpobwXnLR9","colab_type":"code","colab":{}},"source":["UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n","\n","model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n","model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"elIhGcH4nNzs","colab_type":"code","colab":{}},"source":["import torch.optim as optim\n","\n","optimizer = optim.Adam(model.parameters())\n","\n","criterion = nn.CrossEntropyLoss()\n","\n","model = model.to(device)\n","criterion = criterion.to(device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EGyTJbswnTH2","colab_type":"code","colab":{}},"source":["def categorical_accuracy(preds, y):\n","    \"\"\"\n","    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n","    \"\"\"\n","    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n","    correct = max_preds.squeeze(1).eq(y)\n","    return correct.sum() / torch.FloatTensor([y.shape[0]])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q-wcbnKInUgo","colab_type":"code","colab":{}},"source":["def train(model, iterator, optimizer, criterion):\n","    \n","    epoch_loss = 0\n","    epoch_acc = 0\n","    \n","    model.train()\n","    \n","    for batch in iterator:\n","        \n","        optimizer.zero_grad()\n","        \n","        predictions = model(batch.text)\n","        \n","        loss = criterion(predictions, batch.label)\n","        \n","        acc = categorical_accuracy(predictions, batch.label)\n","        \n","        loss.backward()\n","        \n","        optimizer.step()\n","        \n","        epoch_loss += loss.item()\n","        epoch_acc += acc.item()\n","        \n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IDjR_k7NnW0m","colab_type":"code","colab":{}},"source":["def evaluate(model, iterator, criterion):\n","    \n","    epoch_loss = 0\n","    epoch_acc = 0\n","    \n","    model.eval()\n","    \n","    with torch.no_grad():\n","    \n","        for batch in iterator:\n","\n","            predictions = model(batch.text)\n","            \n","            loss = criterion(predictions, batch.label)\n","            \n","            acc = categorical_accuracy(predictions, batch.label)\n","\n","            epoch_loss += loss.item()\n","            epoch_acc += acc.item()\n","        \n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4wWP6fvSnY6v","colab_type":"code","colab":{}},"source":["import time\n","\n","def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8ojIdv8Fna1F","colab_type":"code","outputId":"91517000-c8a8-4ee5-cebf-4bf09ffc80bc","executionInfo":{"status":"ok","timestamp":1588500852610,"user_tz":-540,"elapsed":75634,"user":{"displayName":"Seoyoung Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjITIRuMxnapYLrcCepnJsCF3Rb52KogXDd9B-Mhg=s64","userId":"04592586031163595245"}},"colab":{"base_uri":"https://localhost:8080/","height":263}},"source":["N_EPOCHS = 5\n","\n","best_valid_loss = float('inf')\n","\n","for epoch in range(N_EPOCHS):\n","\n","    start_time = time.time()\n","    \n","    train_loss, train_acc = train(model, train_iter, optimizer, criterion)\n","    valid_loss, valid_acc = evaluate(model, valid_iter, criterion)\n","    \n","    end_time = time.time()\n","\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","    \n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), 'tut5-model.pt')\n","    \n","    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch: 01 | Epoch Time: 0m 14s\n","\tTrain Loss: 0.127 | Train Acc: 95.59%\n","\t Val. Loss: 0.330 |  Val. Acc: 90.84%\n","Epoch: 02 | Epoch Time: 0m 14s\n","\tTrain Loss: 0.107 | Train Acc: 96.27%\n","\t Val. Loss: 0.361 |  Val. Acc: 90.88%\n","Epoch: 03 | Epoch Time: 0m 14s\n","\tTrain Loss: 0.089 | Train Acc: 96.95%\n","\t Val. Loss: 0.399 |  Val. Acc: 90.24%\n","Epoch: 04 | Epoch Time: 0m 14s\n","\tTrain Loss: 0.078 | Train Acc: 97.37%\n","\t Val. Loss: 0.426 |  Val. Acc: 90.39%\n","Epoch: 05 | Epoch Time: 0m 14s\n","\tTrain Loss: 0.069 | Train Acc: 97.65%\n","\t Val. Loss: 0.463 |  Val. Acc: 90.38%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FW34JrkUBm0z","colab_type":"code","outputId":"a0f2a00d-5143-4476-ee50-12f26224b124","executionInfo":{"status":"ok","timestamp":1588500856059,"user_tz":-540,"elapsed":1643,"user":{"displayName":"Seoyoung Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjITIRuMxnapYLrcCepnJsCF3Rb52KogXDd9B-Mhg=s64","userId":"04592586031163595245"}},"colab":{"base_uri":"https://localhost:8080/","height":32}},"source":["# EPOCH = 5\n","\n","model.load_state_dict(torch.load('tut5-model.pt'))\n","\n","test_loss, test_acc = evaluate(model, test_iter, criterion)\n","\n","print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Test Loss: 0.346 | Test Acc: 90.45%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"g30EOrKKB9JB","colab_type":"code","outputId":"62358aa0-0e36-40b2-a20b-6975c334a79c","executionInfo":{"status":"ok","timestamp":1588501033311,"user_tz":-540,"elapsed":147661,"user":{"displayName":"Seoyoung Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjITIRuMxnapYLrcCepnJsCF3Rb52KogXDd9B-Mhg=s64","userId":"04592586031163595245"}},"colab":{"base_uri":"https://localhost:8080/","height":510}},"source":["N_EPOCHS = 10\n","\n","best_valid_loss = float('inf')\n","\n","for epoch in range(N_EPOCHS):\n","\n","    start_time = time.time()\n","    \n","    train_loss, train_acc = train(model, train_iter, optimizer, criterion)\n","    valid_loss, valid_acc = evaluate(model, valid_iter, criterion)\n","    \n","    end_time = time.time()\n","\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","    \n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), 'tut5-model.pt')\n","    \n","    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch: 01 | Epoch Time: 0m 14s\n","\tTrain Loss: 0.110 | Train Acc: 96.22%\n","\t Val. Loss: 0.363 |  Val. Acc: 90.91%\n","Epoch: 02 | Epoch Time: 0m 14s\n","\tTrain Loss: 0.090 | Train Acc: 96.88%\n","\t Val. Loss: 0.407 |  Val. Acc: 90.31%\n","Epoch: 03 | Epoch Time: 0m 14s\n","\tTrain Loss: 0.080 | Train Acc: 97.26%\n","\t Val. Loss: 0.444 |  Val. Acc: 90.50%\n","Epoch: 04 | Epoch Time: 0m 14s\n","\tTrain Loss: 0.066 | Train Acc: 97.75%\n","\t Val. Loss: 0.479 |  Val. Acc: 90.30%\n","Epoch: 05 | Epoch Time: 0m 14s\n","\tTrain Loss: 0.060 | Train Acc: 97.93%\n","\t Val. Loss: 0.512 |  Val. Acc: 90.27%\n","Epoch: 06 | Epoch Time: 0m 14s\n","\tTrain Loss: 0.055 | Train Acc: 98.18%\n","\t Val. Loss: 0.550 |  Val. Acc: 90.23%\n","Epoch: 07 | Epoch Time: 0m 14s\n","\tTrain Loss: 0.051 | Train Acc: 98.31%\n","\t Val. Loss: 0.573 |  Val. Acc: 89.96%\n","Epoch: 08 | Epoch Time: 0m 14s\n","\tTrain Loss: 0.046 | Train Acc: 98.50%\n","\t Val. Loss: 0.620 |  Val. Acc: 89.75%\n","Epoch: 09 | Epoch Time: 0m 14s\n","\tTrain Loss: 0.044 | Train Acc: 98.58%\n","\t Val. Loss: 0.640 |  Val. Acc: 89.80%\n","Epoch: 10 | Epoch Time: 0m 14s\n","\tTrain Loss: 0.041 | Train Acc: 98.73%\n","\t Val. Loss: 0.691 |  Val. Acc: 89.91%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mzeuacD4nvOB","colab_type":"code","outputId":"d006b0c1-5977-46ed-c058-043921814ba1","executionInfo":{"status":"ok","timestamp":1588501036396,"user_tz":-540,"elapsed":1462,"user":{"displayName":"Seoyoung Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjITIRuMxnapYLrcCepnJsCF3Rb52KogXDd9B-Mhg=s64","userId":"04592586031163595245"}},"colab":{"base_uri":"https://localhost:8080/","height":32}},"source":["# EPOCH = 10\n","\n","model.load_state_dict(torch.load('tut5-model.pt'))\n","\n","test_loss, test_acc = evaluate(model, test_iter, criterion)\n","\n","print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Test Loss: 0.378 | Test Acc: 90.50%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_RB3Qa9O184x","colab_type":"text"},"source":["# RNN"]},{"cell_type":"code","metadata":{"id":"KoVdz6tt2e-q","colab_type":"code","colab":{}},"source":["class RNN(nn.Module):\n","    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n","        \n","        super().__init__()\n","        \n","        self.embedding = nn.Embedding(input_dim, embedding_dim)\n","        \n","        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n","        \n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","        \n","    def forward(self, text):\n","\n","        #text = [sent len, batch size]\n","        \n","        embedded = self.embedding(text)\n","        \n","        #embedded = [sent len, batch size, emb dim]\n","        \n","        output, hidden = self.rnn(embedded)\n","        \n","        #output = [sent len, batch size, hid dim]\n","        #hidden = [1, batch size, hid dim]\n","        \n","        assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n","        \n","        return self.fc(hidden.squeeze(0))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bCNrrcd_2oxa","colab_type":"code","colab":{}},"source":["INPUT_DIM = len(TEXT.vocab)\n","EMBEDDING_DIM = 100\n","HIDDEN_DIM = 256\n","OUTPUT_DIM = len(LABEL.vocab)\n","\n","model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6se-AWzP2u_S","colab_type":"code","outputId":"734184de-df44-4bc1-ace5-0595bf58b583","executionInfo":{"status":"ok","timestamp":1588501103980,"user_tz":-540,"elapsed":1030,"user":{"displayName":"Seoyoung Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjITIRuMxnapYLrcCepnJsCF3Rb52KogXDd9B-Mhg=s64","userId":"04592586031163595245"}},"colab":{"base_uri":"https://localhost:8080/","height":32}},"source":["def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f'The model has {count_parameters(model):,} trainable parameters')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["The model has 2,592,876 trainable parameters\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"B5zUot9I2v0u","colab_type":"code","colab":{}},"source":["import torch.optim as optim\n","\n","optimizer = optim.SGD(model.parameters(), lr=1e-3)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FXIFHsc13AU4","colab_type":"code","colab":{}},"source":["criterion = nn.CrossEntropyLoss() ### changed"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3DvFi6Rw3CQD","colab_type":"code","colab":{}},"source":["model = model.to(device)\n","criterion = criterion.to(device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SMhrqHJW3Kxw","colab_type":"code","colab":{}},"source":["def categorical_accuracy(preds, y):\n","    \"\"\"\n","    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n","    \"\"\"\n","    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n","    correct = max_preds.squeeze(1).eq(y)\n","    return correct.sum() / torch.FloatTensor([y.shape[0]])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1l-7f1C63LKN","colab_type":"code","colab":{}},"source":["def train(model, iterator, optimizer, criterion):\n","    \n","    epoch_loss = 0\n","    epoch_acc = 0\n","    \n","    model.train()\n","    \n","    for batch in iterator:\n","        \n","        optimizer.zero_grad()\n","                \n","        predictions = model(batch.text).squeeze(1)\n","        \n","        loss = criterion(predictions, batch.label)\n","        \n","        acc = categorical_accuracy(predictions, batch.label)\n","        \n","        loss.backward()\n","        \n","        optimizer.step()\n","        \n","        epoch_loss += loss.item()\n","        epoch_acc += acc.item()\n","        \n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EOVP5DfW3SE9","colab_type":"code","colab":{}},"source":["def evaluate(model, iterator, criterion):\n","    \n","    epoch_loss = 0\n","    epoch_acc = 0\n","    \n","    model.eval()\n","    \n","    with torch.no_grad():\n","    \n","        for batch in iterator:\n","\n","            predictions = model(batch.text).squeeze(1)\n","            \n","            loss = criterion(predictions, batch.label)\n","            \n","            acc = categorical_accuracy(predictions, batch.label)\n","\n","            epoch_loss += loss.item()\n","            epoch_acc += acc.item()\n","        \n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jz1iIKgU3Vxs","colab_type":"code","outputId":"42e4265a-797a-48f9-dc3c-d933d0f4cd5e","executionInfo":{"status":"ok","timestamp":1588501378605,"user_tz":-540,"elapsed":55766,"user":{"displayName":"Seoyoung Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjITIRuMxnapYLrcCepnJsCF3Rb52KogXDd9B-Mhg=s64","userId":"04592586031163595245"}},"colab":{"base_uri":"https://localhost:8080/","height":263}},"source":["N_EPOCHS = 5\n","\n","best_valid_loss = float('inf')\n","\n","for epoch in range(N_EPOCHS):\n","\n","    start_time = time.time()\n","    \n","    train_loss, train_acc = train(model, train_iter, optimizer, criterion)\n","    valid_loss, valid_acc = evaluate(model, valid_iter, criterion)\n","    \n","    end_time = time.time()\n","\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","    \n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), 'tut1-model.pt')\n","    \n","    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch: 01 | Epoch Time: 0m 11s\n","\tTrain Loss: 1.385 | Train Acc: 25.31%\n","\t Val. Loss: 1.386 |  Val. Acc: 24.82%\n","Epoch: 02 | Epoch Time: 0m 10s\n","\tTrain Loss: 1.385 | Train Acc: 24.96%\n","\t Val. Loss: 1.386 |  Val. Acc: 24.82%\n","Epoch: 03 | Epoch Time: 0m 10s\n","\tTrain Loss: 1.385 | Train Acc: 25.18%\n","\t Val. Loss: 1.386 |  Val. Acc: 25.19%\n","Epoch: 04 | Epoch Time: 0m 11s\n","\tTrain Loss: 1.385 | Train Acc: 25.23%\n","\t Val. Loss: 1.386 |  Val. Acc: 25.19%\n","Epoch: 05 | Epoch Time: 0m 10s\n","\tTrain Loss: 1.384 | Train Acc: 25.11%\n","\t Val. Loss: 1.386 |  Val. Acc: 24.90%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KB4CooCPDTxz","colab_type":"code","outputId":"85d6ef26-9fde-4eb8-cde3-dfc225e391ac","executionInfo":{"status":"ok","timestamp":1588501317166,"user_tz":-540,"elapsed":1551,"user":{"displayName":"Seoyoung Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjITIRuMxnapYLrcCepnJsCF3Rb52KogXDd9B-Mhg=s64","userId":"04592586031163595245"}},"colab":{"base_uri":"https://localhost:8080/","height":32}},"source":["model.load_state_dict(torch.load('tut1-model.pt'))\n","\n","test_loss, test_acc = evaluate(model, test_iter, criterion)\n","\n","print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Test Loss: 1.386 | Test Acc: 25.30%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Gq0CmSiwphYN","colab_type":"text"},"source":["# LSTM"]},{"cell_type":"markdown","metadata":{"id":"iFL23a6JEAql","colab_type":"text"},"source":["We'll be using packed padded sequences, which will make our RNN only process the non-padded elements of our sequence, and for any padded element the output will be a zero tensor. To use packed padded sequences, we have to tell the RNN how long the actual sequences are. We do this by setting include_lengths = True for our TEXT field. This will cause batch.text to now be a tuple with the first element being our sentence (a numericalized tensor that has been padded) and the second element being the actual lengths of our sentences."]},{"cell_type":"code","metadata":{"id":"YkCIaRCmD47_","colab_type":"code","colab":{}},"source":["import random\n","\n","SEED = 1234 # Random Seed for reproductivity\n","\n","torch.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True\n","\n","TEXT = data.Field(tokenize = 'spacy', include_lengths = True)\n","LABEL = data.LabelField()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HqoKtZL4EEjX","colab_type":"code","colab":{}},"source":["from torchtext.data import TabularDataset\n","\n","# put the train and text csv to PATH\n","DATA_PATH = '/content/drive/My Drive/lottery-ticket-hypothesis-for-text-classification/data/ag_news_csv/'\n","\n","train = data.TabularDataset(path = DATA_PATH + 'train.csv', format = 'csv', fields = [('text', TEXT), ('label', LABEL)], skip_header = False)\n","test = data.TabularDataset(path = DATA_PATH + 'test.csv', format = 'csv', fields = [('text', TEXT), ('label', LABEL)], skip_header = False)\n","\n","# make splits for data\n","# by default this splits 70:30\n","train, valid = train.split(split_ratio = 0.7, random_state = random.seed(SEED))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"34ZDh2oREFD6","colab_type":"code","outputId":"2f3fb219-96b9-42bf-b2d6-2493b2668675","executionInfo":{"status":"ok","timestamp":1588504387961,"user_tz":-540,"elapsed":591,"user":{"displayName":"‍홍서영[학생](경영대학 경영학과)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiIddZ52JepimokQVw6hJ6jkjyxEwfdpS2JIyj5=s64","userId":"07488608218318880996"}},"colab":{"base_uri":"https://localhost:8080/","height":135}},"source":["print(f'Number of training examples: {len(train)}')\n","print(f'Number of training examples: {len(valid)}')\n","print(f'Number of testing examples: {len(test)}')\n","\n","print(vars(train.examples[0]))\n","print(vars(valid.examples[0]))\n","print(vars(test.examples[0]))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Number of training examples: 84000\n","Number of training examples: 36000\n","Number of testing examples: 7600\n","{'text': ['In', '30', 'sorties', 'on', 'Monday', ',', 'U.S.', 'helicopters', 'delivered', 'more', 'than', '60,000', 'pounds', 'of', 'water', ',', 'medical', 'supplies', 'and', 'food', '.'], 'label': '1'}\n","{'text': ['London', '-', 'US', 'sports', 'tycoon', 'Malcolm', 'Glazer', 'was', 'trying', 'to', 'win', 'over', 'Manchester', 'United', '#', '39;s', 'two', 'key', 'Irish', 'shareholders', 'in', 'his', 'bid', 'to', 'buy', 'the', 'English', 'soccer', 'club', ',', 'but', 'had', 'not', 'yet', 'entered', 'serious', 'talks', 'with', 'them', ',', 'sources', 'familiar', 'with', 'the', 'situation', 'said', 'yesterday', '.'], 'label': '2'}\n","{'text': ['Unions', 'representing', 'workers', 'at', 'Turner', '  ', 'Newall', 'say', 'they', 'are', \"'\", 'disappointed', \"'\", 'after', 'talks', 'with', 'stricken', 'parent', 'firm', 'Federal', 'Mogul', '.'], 'label': '3'}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DWjXLQWmENZX","colab_type":"code","outputId":"97373432-da3d-45fa-b6ab-778a16de33d1","executionInfo":{"status":"ok","timestamp":1588504392473,"user_tz":-540,"elapsed":2500,"user":{"displayName":"‍홍서영[학생](경영대학 경영학과)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiIddZ52JepimokQVw6hJ6jkjyxEwfdpS2JIyj5=s64","userId":"07488608218318880996"}},"colab":{"base_uri":"https://localhost:8080/","height":65}},"source":["MAX_VOCAB_SIZE = 25_000\n","\n","TEXT.build_vocab(train, \n","                 max_size = MAX_VOCAB_SIZE, \n","                 vectors = \"glove.6B.100d\", \n","                 unk_init = torch.Tensor.normal_)\n","\n","LABEL.build_vocab(train)\n","\n","print (\"Length of Text Vocabulary: \" + str(len(TEXT.vocab)))\n","print (\"Vector size of Text Vocabulary: \", TEXT.vocab.vectors.size())\n","print (\"Label Length: \" + str(len(LABEL.vocab)))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Length of Text Vocabulary: 25002\n","Vector size of Text Vocabulary:  torch.Size([25002, 100])\n","Label Length: 4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rvaUcWFaESBc","colab_type":"code","colab":{}},"source":["BATCH_SIZE = 64\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","train_iter, valid_iter, test_iter = data.BucketIterator.splits(\n","    (train, valid, test), \n","    sort_key = lambda x: x.text,\n","    batch_size = BATCH_SIZE,\n","    device = device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UGBwDc_qr7A1","colab_type":"code","colab":{}},"source":["class LSTM(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n","                 bidirectional, dropout, pad_idx):\n","        \n","        super().__init__()\n","        \n","        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n","        \n","        self.rnn = nn.LSTM(embedding_dim, \n","                           hidden_dim, \n","                           num_layers=n_layers, \n","                           bidirectional=bidirectional, \n","                           dropout=dropout)\n","        \n","        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n","        \n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, text, text_lengths):\n","        \n","        #text = [sent len, batch size]\n","        \n","        embedded = self.dropout(self.embedding(text))\n","        \n","        #embedded = [sent len, batch size, emb dim]\n","        \n","        #pack sequence\n","        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths, enforce_sorted=False)\n","        \n","        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n","        \n","        #unpack sequence\n","        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n","\n","        #output = [sent len, batch size, hid dim * num directions]\n","        #output over padding tokens are zero tensors\n","        \n","        #hidden = [num layers * num directions, batch size, hid dim]\n","        #cell = [num layers * num directions, batch size, hid dim]\n","        \n","        #concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n","        #and apply dropout\n","        \n","        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n","                \n","        #hidden = [batch size, hid dim * num directions]\n","            \n","        return self.fc(hidden)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"012otSy3MyhY","colab_type":"code","colab":{}},"source":["INPUT_DIM = len(TEXT.vocab)\n","EMBEDDING_DIM = 100\n","HIDDEN_DIM = 256\n","OUTPUT_DIM = len(LABEL.vocab)\n","N_LAYERS = 2\n","BIDIRECTIONAL = True\n","DROPOUT = 0.5\n","PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n","\n","model = LSTM(INPUT_DIM, \n","            EMBEDDING_DIM, \n","            HIDDEN_DIM, \n","            OUTPUT_DIM, \n","            N_LAYERS, \n","            BIDIRECTIONAL, \n","            DROPOUT, \n","            PAD_IDX)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GQ-TxAzvFPBN","colab_type":"code","outputId":"6b2b4fd6-cc6e-4d14-993d-00a19dd8c0b7","executionInfo":{"status":"ok","timestamp":1588504404492,"user_tz":-540,"elapsed":457,"user":{"displayName":"‍홍서영[학생](경영대학 경영학과)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiIddZ52JepimokQVw6hJ6jkjyxEwfdpS2JIyj5=s64","userId":"07488608218318880996"}},"colab":{"base_uri":"https://localhost:8080/","height":32}},"source":["def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f'The model has {count_parameters(model):,} trainable parameters')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["The model has 4,812,396 trainable parameters\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qS-a0PEgFTdM","colab_type":"code","outputId":"99e34c30-2250-4dd2-b7c5-f89c63e68147","executionInfo":{"status":"ok","timestamp":1588504406771,"user_tz":-540,"elapsed":577,"user":{"displayName":"‍홍서영[학생](경영대학 경영학과)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiIddZ52JepimokQVw6hJ6jkjyxEwfdpS2JIyj5=s64","userId":"07488608218318880996"}},"colab":{"base_uri":"https://localhost:8080/","height":32}},"source":["pretrained_embeddings = TEXT.vocab.vectors\n","\n","print(pretrained_embeddings.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([25002, 100])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"z-25iPL3GGAV","colab_type":"code","outputId":"8ad6413a-4968-4599-89d0-65d165636db4","executionInfo":{"status":"ok","timestamp":1588504407570,"user_tz":-540,"elapsed":370,"user":{"displayName":"‍홍서영[학생](경영대학 경영학과)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiIddZ52JepimokQVw6hJ6jkjyxEwfdpS2JIyj5=s64","userId":"07488608218318880996"}},"colab":{"base_uri":"https://localhost:8080/","height":131}},"source":["model.embedding.weight.data.copy_(pretrained_embeddings)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-0.1117, -0.4966,  0.1631,  ...,  1.2647, -0.2753, -0.1325],\n","        [-0.8555, -0.7208,  1.3755,  ...,  0.0825, -1.1314,  0.3997],\n","        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n","        ...,\n","        [-0.4598,  1.1272, -1.1509,  ..., -0.6062,  0.1021,  0.8086],\n","        [ 0.1967, -2.3082,  0.2116,  ...,  0.9473,  0.1453, -0.7713],\n","        [ 0.0786,  0.3827, -1.8876,  ..., -0.1305, -0.2890, -0.5978]])"]},"metadata":{"tags":[]},"execution_count":104}]},{"cell_type":"code","metadata":{"id":"7FgQuO6cGGeO","colab_type":"code","outputId":"8dbfa717-162c-41e3-ecdc-e51aca0bccc8","executionInfo":{"status":"ok","timestamp":1588504409660,"user_tz":-540,"elapsed":564,"user":{"displayName":"‍홍서영[학생](경영대학 경영학과)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiIddZ52JepimokQVw6hJ6jkjyxEwfdpS2JIyj5=s64","userId":"07488608218318880996"}},"colab":{"base_uri":"https://localhost:8080/","height":131}},"source":["UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n","\n","model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n","model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n","\n","print(model.embedding.weight.data)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n","        ...,\n","        [-0.4598,  1.1272, -1.1509,  ..., -0.6062,  0.1021,  0.8086],\n","        [ 0.1967, -2.3082,  0.2116,  ...,  0.9473,  0.1453, -0.7713],\n","        [ 0.0786,  0.3827, -1.8876,  ..., -0.1305, -0.2890, -0.5978]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xKDFIzaNGH9B","colab_type":"code","colab":{}},"source":["import torch.optim as optim\n","\n","optimizer = optim.Adam(model.parameters())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"u7WMwVknGVGG","colab_type":"code","colab":{}},"source":["criterion = nn.CrossEntropyLoss()\n","model = model.to(device)\n","criterion = criterion.to(device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"juyyozeEyh50","colab_type":"code","colab":{}},"source":["def train(model, iterator, optimizer, criterion):\n","    \n","    epoch_loss = 0\n","    epoch_acc = 0\n","    \n","    model.train()\n","    \n","    for batch in iterator:\n","        \n","        optimizer.zero_grad()\n","\n","        text, text_lengths = batch.text\n","        \n","        predictions = model(text, text_lengths).squeeze(1)\n","        \n","        loss = criterion(predictions, batch.label)\n","        \n","        acc = categorical_accuracy(predictions, batch.label)\n","        \n","        loss.backward()\n","        \n","        optimizer.step()\n","        \n","        epoch_loss += loss.item()\n","        epoch_acc += acc.item()\n","        \n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n","\n","def evaluate(model, iterator, criterion):\n","    \n","    epoch_loss = 0\n","    epoch_acc = 0\n","    \n","    model.eval()\n","    \n","    with torch.no_grad():\n","    \n","        for batch in iterator:\n","\n","            text, text_lengths = batch.text\n","\n","            predictions = model(text, text_lengths).squeeze(1)\n","            \n","            loss = criterion(predictions, batch.label)\n","            \n","            acc = categorical_accuracy(predictions, batch.label)\n","\n","            epoch_loss += loss.item()\n","            epoch_acc += acc.item()\n","        \n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8-YhIj8wG3k5","colab_type":"code","colab":{}},"source":["import time\n","\n","def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ISAL8kkOPEpS","colab_type":"code","outputId":"b56954e4-aa2a-4ba7-d322-f2796b97278f","executionInfo":{"status":"ok","timestamp":1588505140893,"user_tz":-540,"elapsed":717473,"user":{"displayName":"‍홍서영[학생](경영대학 경영학과)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiIddZ52JepimokQVw6hJ6jkjyxEwfdpS2JIyj5=s64","userId":"07488608218318880996"}},"colab":{"base_uri":"https://localhost:8080/","height":263}},"source":["N_EPOCHS = 5\n","\n","best_valid_loss = float('inf')\n","\n","for epoch in range(N_EPOCHS):\n","\n","    start_time = time.time()\n","    \n","    train_loss, train_acc = train(model, train_iter, optimizer, criterion)\n","    valid_loss, valid_acc = evaluate(model, valid_iter, criterion)\n","    \n","    end_time = time.time()\n","\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","    \n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), 'tut2-model.pt')\n","    \n","    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch: 01 | Epoch Time: 2m 23s\n","\tTrain Loss: 0.528 | Train Acc: 80.80%\n","\t Val. Loss: 0.339 |  Val. Acc: 88.56%\n","Epoch: 02 | Epoch Time: 2m 22s\n","\tTrain Loss: 0.348 | Train Acc: 87.92%\n","\t Val. Loss: 0.276 |  Val. Acc: 90.48%\n","Epoch: 03 | Epoch Time: 2m 23s\n","\tTrain Loss: 0.292 | Train Acc: 89.96%\n","\t Val. Loss: 0.262 |  Val. Acc: 91.19%\n","Epoch: 04 | Epoch Time: 2m 23s\n","\tTrain Loss: 0.260 | Train Acc: 91.02%\n","\t Val. Loss: 0.250 |  Val. Acc: 91.33%\n","Epoch: 05 | Epoch Time: 2m 23s\n","\tTrain Loss: 0.234 | Train Acc: 91.88%\n","\t Val. Loss: 0.235 |  Val. Acc: 91.86%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aQe4_UV7PE3U","colab_type":"code","outputId":"afc84a7b-9de9-4905-f471-60cac36ebbb5","executionInfo":{"status":"ok","timestamp":1588505166973,"user_tz":-540,"elapsed":4123,"user":{"displayName":"‍홍서영[학생](경영대학 경영학과)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiIddZ52JepimokQVw6hJ6jkjyxEwfdpS2JIyj5=s64","userId":"07488608218318880996"}},"colab":{"base_uri":"https://localhost:8080/","height":32}},"source":["model.load_state_dict(torch.load('tut2-model.pt'))\n","\n","test_loss, test_acc = evaluate(model, test_iter, criterion)\n","\n","print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Test Loss: 0.250 | Test Acc: 91.20%\n"],"name":"stdout"}]}]}